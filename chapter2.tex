\chapter{Параметрична модель наборів даних із частково-помилковими анотаціями та метод їх генерації}
\label{data-arch}
Для систематизованого вивчення впливу помилок в анотаціях, та оцінки відповідного впливу запропонованих рішень, розроблено модель набору даних із частково-помилковими анотаціями семантичної сегментації, що відповідає оцінкам моделей шуму в різних задачах автоматизованого скринінгу. 


\section{Методи оцінки якості класифікації та сегментації зображень в задачі автоматизованого скринінгу}

Для тестування моделей та методів машинного навчання, необхідно визначити метрики, за якими оцінюється достовірність передбачень. В задачах класифікації та сегментації використовуються наступні метрики.

\subsection{Помилки 1 і 2 роду та матриця невідповідностей}

В задачах математичної статистики, помилка першого роду - це хибне відхилення правильної  гіпотези (хибно-позитивний результат, FP), тоді як помилка другого роду - це прийняття хибної гіпотези (хибно-негативний результат, FN). Дані поняття використовуються, коли потрібно прийняття бінарного рішення на основі деякого критерію, що може мати похибку.

В задачах контрольованого навчання, зокрема бінарної класифікації та сегментації, за нульову гіпотезу зазвичай приймається приналежність елемента вибірки до класу, що зустрічається в виборці частіше. Також, в задачах багатокласової класифікації використовується розширення поняття помилок першого і другого роду на задачу з більшою кількістю гіпотез - матриця невідповідностей. Матриця невідповідностей - це матриця, в строках якої зазначені зразки прогнозованого класу, а кожен із стовпців представляє зразки справжнього класу. Така матриця дозволяє оцінити, чи допускає система невідповідності між класами. 

\subsection{Влучність, чутливість та специфічність}

Влучність, чутливість та специфічність є похідними мірами якості бінарного класифікатора та розраховуються на основі значень в матриці невідповідностей.
Влучність (англ. precision) - вимірює частку істинно-позитивних зразків серед знайдених.
\begin{equation}
	Precision = \frac{TP}{TP+FP}
\end{equation}

Чутливість, або повнота (англ. sensitivity, recall) - вимірює частку істинно-позитивних зразків серед усіх позитивних зразків.
\begin{equation}
	Recall = \frac{TP}{TP+FN}
\end{equation}

Специфічність (англ. specificity) - вимірює частку істинно-негативних зразків серед усіх негативних зразків. 
\begin{equation}
	Specificity = \frac{TN}{TN+FP}
\end{equation}

Між влучністю і повнотою, та чутливістю і специфічністю існує обернена залежність, коли можливо підвищити одну ціною зниження іншої. Через наявність такої залежноси, на практиці, ці міри не використовуються окремо. Замість цього використовують агреговані метрики, що дозволяють оцінити якість класифікатора в цілому.

\subsection{Міра F1 та індекс подібності Дайса-Соренсена}

F1 та індекс подібності Дайса-Соренсена (\textit{англ. Dice score}) є еквівалентними мірами, що, зазвичай використовуються в задачах класифікації (F1-міра) та сегментації (Dice score). 

Міра F1 визначається як середнє гармонічне між влучністю та повнотою:
\begin{equation}
	F1 = \frac{2}{precision^{-1} + recall^{-1}}=2 \cdot \frac{precision \cdot recall}{precision + recall} = \frac{2TP}{2TP+FP+FN}
\end{equation}

Індекс подібності Соренсена визначається на множинах, і, в задачах сегментації, визначається на піксельних масках сегментації:
\begin{equation}
	D_c = 2 \cdot \frac{A \cap B}{|A| + |B|}
\end{equation}

Також, для бінарних даних $A \cap B$ відповідає $TP$, а $|A| + |B|$ відповідає всій множині об'єктів, тобто еквівалентно $TP + FP + FN$. Таким чином, коефіцієнт Соренсена є еквівалентним мірі F1.








\section{Модель набору даних із частково-помилковими анотаціями}

На основі проведеного аналізу виявлено, що основними проблемами в анотації для задачі сегментації планарних зображень в задачах скринінгу є:

\begin{itemize}
	\item Маски сегментації, що захоплюють сусідні з об'єктом пікселі;
	\item Маски сегментації, що покривають об'єкт не повністю;
	\item Відсутні маски сегментації для деяких об'єктів;
	\item Присутні зайві маски на місцях, де немає об'єктів.
\end{itemize}

Для відображення означених помилок в анотаціях, запропоновано штучне введення помилок за допомогою випадкового застосування морфологічних операцій ерозії та дилатації з квадратним ядром до масок сегментації окремих об'єктів перед додаванням їх до загальної маски. 

Операції ерозії та дилатації відповідають неупередженим помилкам, оскільки за їхнім результатом не можна відновити вихідну конфігурацію маски \cite{vorontsov2021annotationefficient}. Також, означені операції реалізують помилки, що залежать від ознак, оскільки нерівномірно модифікують тонкі та більш товсті лінії, а також порожнини та опуклості. 

На відміну від геометричних перетворень маски, включення, або невключення пікселів з граничних регіонів маски є частішим випадком помилок в анотаціях задачі сегментації. 

Запропонована модель набору даних $\mathcal{M}$ має наступне представлення: 
\begin{equation}
	\label{eqn:model_Def}
	\mathcal{M} \in \{ \mathcal{X}_{b}, \mathcal{X}_{tex}, N, S_{img}, S_{obj}, \Delta_{max}, N_{obj}, P_e, P_d, S_e, S_d \}
\end{equation}

де $\mathcal{X}_{b}$ - набір зображень фону, 
$\mathcal{X}_{f}$ - набір об'єктів,  
$\mathcal{X}_{tex}$ - набір зображень текстур об'єктів, 
$N$ - кількість зображень в генерованому наборі даних, 
$S_{img}$ - розмір генерованих зображень в пікселях,
$S_{obj}$ - середній розмір об'єкта в пікселях,
$\Delta_{max}$ - максимальне відхилення розміру об'єкта в відсотках,
$N_{obj}$ - максимальна кількість об'єктів на зображенні,
$P_e$ та $P_d$ - ймовірності зменшення та збільшення маски кожного з об'єктів,
$S_e$ та $S_d$ - допустимі масштаби збільшення та зменшення масок всіх об'єктів. 	

Останні чотири параметри введено для контрольованого створення помилок в анотаціях.

\section{Метод генерації наборів даних}

Запропоновано метод контрольованої генерації як зображень, так і масок сегментації що модифікуються відповідно до випадково обраних помилок.

На основі параметричної моделі генеруються навчальний та тестовий набори даних, всі зображення в наборах генеруються незалежно.

Контрольована генерація зображень виконується в два етапи: генерація фону та розташування на ньому довільної кількості об'єктів. Для генерації фону можуть бути використані як звичайні натуральні зображення, так і синтетичні текстури, чи заливка константним кольором. В якості об'єктів можуть бути використані зображення з наборів даних MNIST \cite{mnist}, або FashionMNIST \cite{fashionmnist}. 

Використання зазначених наборів даних зумовлено трьома факторами: 

\begin{itemize}
	\item Можливість простого відділення об'єкта від вихідного фону;
	\item Наявність схожих елементів в різних класів (наприклад, цифри 1 та 7, або класи \textit{T-shirt} та \textit{Dress});
	\item Висока точність роботи сучасних нейронних мереж на цих наборах даних, що дозволяє сконцентруватися на впливі помилок в розмітці, замість розпізнавання безпосередньо об'єктів
\end{itemize}


На основі запропонованої параметричної моделі (\ref{eqn:model_Def}) розроблено метод генерації наборів даних із частково-помилковими анотаціями, який містить наступні кроки: 

1. Вибрати випадкове зображення фону: $x_{bg} \sim \mathcal{X}_b$

2. Вибрати кількість об'єктів на зображенні: $N_{obj} \sim \mathcal{U}(1, N_{obj})$

3. Провести ініціалізацію маски сегментації: $M = 0 \; \text{так що} \; M \in \mathcal{R}^{C \times S_{img} \times S_{img}}$

4. Виконати наступні кроки $n_{obj}$ разів:

\qquad 4.1 Вибрати розміри об'єкта: $s \sim \mathcal{U}(S_{obj} - \Delta_{max}, S_{obj} + \Delta_{max})$

\qquad 4.2 Вибрати координати розміщення об'єкта: 
\begin{align*}
	i_f &\sim \mathcal{U}(0, S_{img} - s)\\
	j_f &\sim \mathcal{U}(0, S_{img} - s)
\end{align*}

\qquad 4.3 Вибрати зображення об'єкта $x_{fg} \sim \mathcal{X}_f$ та відповідний клас об'єкта $c_{fg} \sim \mathcal{Y}_f$

\qquad 4.4 Змінити розмір зображення об'єкта за допомогою білінійної інтерполяції: 
\begin{align*}
	\hat{x}_{fg} = R_{bilinear}(x_{fg})
\end{align*}

\qquad 4.5 Вибрати зображення текстури $x_{tex} \sim \mathcal{X}_{tex}$

\qquad 4.6 Модифікувати зображення об'єкта за допомогою текстури:
\begin{equation*}
	\hat{x}_{fg} = x_{fg} \circ x_{tex}[i_f:i_f+s, j_f:j_f+s]
\end{equation*}

\qquad 4.7 Розмістити зображення об'єкта на зображенні фону:
\begin{equation*}
	x_{bg}[i_f:i_f+s, j_f:j_f+s] = (1 - x_{fg}) \circ x_{bg} + \hat{x}_{fg}
\end{equation*}

\qquad 4.8 Сформувати маску сегментації об'єкта: 
\begin{equation*}
	M_{seg} = x_{fg} > \theta_{seg}
\end{equation*}
де $\theta_{seg}$ - поріг бінаризації вихідного зображення об'єкта. Для набору даних MNIST $\theta_{seg} = 0.2$, для набору даних FashionMNIST $\theta_{seg} = 0.1$.

\qquad 4.9 Модифікувати маску сегментації відповідно до необхідного рівня помилок:
\begin{equation*}
	M_{seg} = 
	\begin{cases}
		M_{seg} \oplus K^{S_d \times S_d} &\text{ якщо } p_d \sim \mathcal{U}(0, 1) < P_d\\
		M_{seg} \ominus K^{S_e \times S_e} &\text{ якщо } p_e \sim \mathcal{U}(0, 1) < P_e
	\end{cases}
\end{equation*}
де $K^{S_d \times S_d}$ - матриця ядра $K^{S_e \times S_e}$ - матриця ядра ерозії.

\qquad 4.10 Розмістити модифіковану маску сегментації об'єкта на загальному зображенні маски сегментації:
\begin{equation*}
	M[c_{fg}, i_f:i_f+s, j_f:j_f+s] = max \; \{ M[c_{fg}, i_f:i_f+s, j_f:j_f+s], M_{seg} \}
\end{equation*}
\qquad 4.11 Зберегти зображення $x_{bg}$ та маску $M$

5. Завершити генерацію

Завдяки такому варіанту генерації, можливо отримання безлічі наборів даних із схожими характеристиками, що дозволяє використовувати непараметричні статистичні методи, такі як бутстрепінг для оцінки моделей. На практиці, для генерації різних наборів даних, достатньо зміни ініціалізації генератора випадкових чисел.

\section{Види згенерованих зображень}

В даному розділі продемонстровано згенеровані зображення та відповідні маски сегментації для різних параметрів моделі. 

За допомогою моделі можна генерувати набори даних з досить різноманітними характеристиками. На рисунках \ref{fig:mnist_clear_bw} та \ref{fig:fmnist_clear_bw} зображено найпростіший випадок для генерації за допомогою моделі: заповнення фону та об'єктів константними значеннями (0 і 1) відповідно.

\begin{figure}[H]
	\centering
	\includegraphics[width=16cm]{generated_model_images/mnist_clear_bw.png}
	\caption{Об'єкти MNIST, фон: константний, колір об'єктів: білий}
	\label{fig:mnist_clear_bw}
\end{figure} 

\begin{figure}[H]
	\centering
	\includegraphics[width=16cm]{generated_model_images/fmnist_clear_bw.png}
	\caption{Об'єкти FashionMNIST, фон: константний, колір об'єктів: білий}
	\label{fig:fmnist_clear_bw}
\end{figure} 

На рисунках \ref{fig:mnist_clear_imagenette} та \ref{fig:fmnist_clear_imagenette} зображено фон з використанням зображення з набору даних Imagenette та заповнення об'єктів константним значенням 1.

\begin{figure}[H]
	\centering
	\includegraphics[width=16cm]{generated_model_images/mnist_clear_imagenette.png}
	\caption{Об'єкти MNIST, фон: Imagenette, колір об'єктів: білий}
	\label{fig:mnist_clear_imagenette}
\end{figure} 


\begin{figure}[H]
	\centering
	\includegraphics[width=16cm]{generated_model_images/fmnist_clear_imagenette.png}
	\caption{Об'єкти FashionMNIST, фон: Imagenette, колір об'єктів: білий}
	\label{fig:fmnist_clear_imagenette}
\end{figure} 

На рисунках \ref{fig:mnist_clear_imagenette_black} та \ref{fig:fmnist_clear_imagenette_black} зображено фон з використанням зображення з набору даних Imagenette та заповнення об'єктів константним значенням 0.

\begin{figure}[H]
	\centering
	\includegraphics[width=16cm]{generated_model_images/mnist_clear_imagenette_black.png}
	\caption{Об'єкти MNIST, фон: Imagenette, колір об'єктів: чорний}
	\label{fig:mnist_clear_imagenette_black}
\end{figure} 


\begin{figure}[H]
	\centering
	\includegraphics[width=16cm]{generated_model_images/fmnist_clear_imagenette_black.png}
	\caption{Об'єкти FashionMNIST, фон: Imagenette, колір об'єктів: чорний}
	\label{fig:fmnist_clear_imagenette_black}
\end{figure} 

На рисунках \ref{fig:mnist_textured_imagenette} зображено найскладніший варіант набору даних: як фон, так і текстури об'єктів взято з набору даних Imagenette.

\begin{figure}[H]
	\centering
	\includegraphics[width=16cm]{generated_model_images/mnist_textured_imagenette.png}
	\caption{Об'єкти MNIST, фон: Imagenette, текстури об'єктів: Imagenette}
	\label{fig:mnist_textured_imagenette}
\end{figure} 

\begin{figure}[H]
	\centering
	\includegraphics[width=16cm]{generated_model_images/fmnist_textured_imagenette.png}
	\caption{Об'єкти FashionMNIST, фон: Imagenette, текстури об'єктів: Imagenette}
	\label{fig:fmnist_textured_imagenette}
\end{figure} 


Для наочності, модифікації масок сегментації показано на простих зображеннях з константним кольором фону та об'єктів.

На рисунку \ref{fig:mnist_erode_50} зображено вихідне зображення, маску сегментації з ерозією ядром $3 \times 3$ та їх комбінацію для наочності.

\begin{figure}[H]
	\centering
	\includegraphics[width=16cm]{generated_model_images/mnist_erode_50.png}
	\caption{Об'єкти MNIST, ерозія маски ядром $3 \times 3$}
	\label{fig:mnist_erode_50}
\end{figure} 

На рисунку \ref{fig:mnist_dilate_50} зображено вихідне зображення, маску сегментації з дилатацією ядром $3 \times 3$ та їх комбінацію для наочності.

\begin{figure}[H]
	\centering
	\includegraphics[width=16cm]{generated_model_images/mnist_dilate_50.png}
	\caption{Об'єкти MNIST, дилатація маски ядром $3 \times 3$}
	\label{fig:mnist_dilate_50}
\end{figure} 

На рисунку \ref{fig:mnist_erode_dilate_50} зображено вихідне зображення, маску сегментації з дилатацією та ерозією ядром $3 \times 3$ та їх комбінацію для наочності.

\begin{figure}[H]
	\centering
	\includegraphics[width=16cm]{generated_model_images/mnist_erode_dilate_50.png}
	\caption{Об'єкти MNIST, ерозія та дилатація маски ядром $3 \times 3$}
	\label{fig:mnist_erode_dilate_50}
\end{figure} 

Також, при виборі розмірів  ядер ерозії потрібно бути уважним до вихідних масок - дуже великі ядра ерозії можуть знищити маску сегментації для об'єкта. На рисунку \ref{fig:mnist_erode_7x7} зображено вихідне зображення, маску сегментації з ерозією ядром $7 \times 7$ та їх комбінацію для наочності.

\begin{figure}[H]
	\centering
	\includegraphics[width=16cm]{generated_model_images/mnist_erode_7x7.png}
	\caption{Об'єкти MNIST, ерозія маски ядром $7 \times 7$}
	\label{fig:mnist_erode_7x7}
\end{figure} 

 


\section{Висновки до другого розділу}

У другому розділі представлено параметричну модель наборів даних із частково-помилковою розміткою для задач сегментації та класифікації, що відповідає оцінкам моделей помилок в різних задачах автоматизованого скринінгу, а також метод контрольованої генерації як зображень, так і масок сегментації та міток класів що модифікуються відповідно до випадково обраних недоліків. 

Запропоновано використання модельних наборів даних тестування достовірності моделей та методів навчання глибоких нейронних мереж в задачах класифікації та семантичної сегментації. Тестування виконується в контрольованих умовах за допомогою введення помилок в розмітку лише тренувального набору даних, в той час як тестувальних набір даних залишається з точною розміткою. 
