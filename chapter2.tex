%TODO: EVERYTHING :(
\chapter{Метод}
2.1 Метод багатозадачного навчання штучних нейронних мереж для роботи в умовах частково помилкової розмітки навчального набору даних в задачах автоматизованого скринінгу (10 страниц)
Использовать задачи, в каждой из которых разный уровень неуверенности
Например, в задаче с шумной разметкой сегментации, наличие классов на картинке будет более точным, а сеть - более уверенной в предсказаниях наличия классов на изображении. 
В задаче классификации с шумной разметкой как классификации, так и сегментации, возможно обучение сети на участках с корректной разметкой и последующим дообучением на неразмеченных участках.
Если задача может быть решена несколькими способами, каждый их этих способов может быть организован как отдельная задача, результаты решения которых будут объединены для получения совместного результата.
Использование нескольких задач снижает чувствительность к неправильно размеченным примерам и повышает способность сети к генерализации

2.1.1 Архітектура штучної нейронної мережі для багатозадачного навчання
Архитектура нейросети основана на Shared trunk подходе, так как используется один и тот же набор данных, и разніе задачи нужно решать для всех данніх в єтом наборе.
При необходимости, интеграция разных видов данных достигается через объединение представлений с нескольких энкодеров. 

2.1.2 Задача класифікації зображень
Использование задачи сегментации как структурированного внимания для регионов, содержащих необходимые для классификации признаки.

2.1.2 Задача семантичної сегментації зображень
Задача сегментации может быть рассмотрена как задача попиксельной классификации. 
/*Вывод условной вероятности при использовании двух классификаторов*/

2.3 Метод сегментації важливих для класифікації ознак зображення в умовах відсутності розмітки для сегментації в навчальному наборі даних
2.3.1 Комбінування задачі класифікації та сегментації 
Использование классификации как маски для отсечения малых ложноположительных регионов в сегментации

2.2 Метод зниження дисперсії прогнозів нейронної мережі за рахунок використання результатів семантично-близьких задач при багатозадачному навчанні
2.2.1 Вимірювання дисперсії прогнозів нейронної мережі
2.2.2 Зниження дисперсії в задачі класифікації
2.2.3 Зниження дисперсії в задачі семантичної сегментації





2.3.2 Напівавтоматичне навчання ШНМ в задачі сегментації
Использование пикселей внутри маски как региона, по которому считаются логиты классификации
При этом полезные для классификации регионы получают высокое значение в маске, а бесполезные - близкое к 0
Важно - использовать L2 регуляризацию, чтобы вся маска на стала единицами

2.3.3 Пост-обробка результатів сегментації 
Вихід маски від CNN безперервним в діапазоні [0, 1). Оскільки декодер сегментації навчається без нагляду, істинний діапазон результатів сегментації неможливо передбачити заздалегідь. Також, в залежності від загального рівня активацій нейронної мережі, він може бути різним для різних вхідних зображень. 
Щоб полегшити калібрування передбачень моделі, використовується пост-обробка, що дозволяє бінарізувати результати сегментації нейронною мережею.  Після того, як маска була бінаризована, до неї застосовується операція морфологічного розкриття квадратним ядром, щоб зменшити кількість малих хибнопозитивних областей.

2.4 Висновки до розділу 2
