%TODO: EVERYTHING :(
\chapter{Метод глибинного багатозадачного навчання}

% 10 страниц
\section{Метод багатозадачного навчання ШНМ в умовах частково помилкової розмітки навчального набору даних}
\subsection{}
% Использование image-level классов как подсказки для улучшения признаков, которые выучивает нейросеть  во время обучения

\subsection{}
% Совмещение регрессии и классификации как задач менее чувствительных к ошибкам во время обучения
% градиенты, опять же, лучше

% 10 страниц
\section{Метод зниження кількості хибно-позитивних прогнозів нейронної мережі за рахунок використання результатів семантично-близьких задач}
\subsection{Використання близьких задач до задачі класифікації}
% Глаза


\subsection{Використання задачі класифікації для покращення семантичної сегментації}
% Вероятностная модель P(Seg | C)


% 10 страниц
\section{Метод сегментації важливих для класифікації ознак зображення в умовах відсутності розмітки для сегментації в навчальному наборі даних}
\subsection{Комбінування задачі класифікації та сегментації}
% Общая формула, структура сети, градиенты


\subsection{Напівавтоматичне навчання ШНМ в задачі сегментації}
% Направление градиентов через нормализацию по матрице и Р(С | S)

\subsection{Пост-обробка результатів сегментації }
% Морфологические трансформации, бинаризация, вот это все


% 2 страницы
\subsection{Висновки до другого розділу}
% Как круо все получилось и пора показать эксперименты
% В экспериментах надо показать сравнение shap и полученного метода для сегментации
