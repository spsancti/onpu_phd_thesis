\chapter{Побудова та випробування системи автоматизованого скринінгу}
В даному розділі розглянуто експерименти із розробленими моделями нейронних мереж та методами їх навчання (розділ \ref{nn-arch}) на синтетичних даних, що були згенеровані за допомогою запропонованої в розділі \ref{data-arch} моделі, а також експерименти, поставлені на наборах даних з реальних задач скринінгу. 


\section{Розробка інструментальних засобів для автоматизованого скринінгу}
Застосування розроблених моделей та методів значно ускладнюється через відсутність інструментальних програмних засобів, що забезпечували б їх роботу. Розробка інструментальних засобів, що реалізують моделі та методи є актуальною задачею.


В даний час швидко розвивається складність програмного забезпечення, що виконує наукові та інженерні задачі. Сучасні системи автоматизованого скринінгу являють собою складні багатокомпонентні системи програмних модулів, які можуть бути фізично розподілені один від одного. Так, наприклад, обладнання для скринінгу може знаходитися безпосередньо в лікарні, в той час як сервіси для обробки даних можуть бути пов'язані з обладнанням, або знаходитися на сторонніх сервісах. Також, все частіше нагальною є потреба зміни модулів в процесі роботи системи, наприклад, при оновленні нейронних мереж, що є їхніми складовими частинами. 

Задача навчання глибоких нейронних мереж є обчислювально-складною задачею, тому для прискорення процесів навчання та прогнозування необхідно використовувати хмарні технології обчислень для задач машинного навчання. 

На основі запропонованих у дисертації моделей, розроблених методів навчання нейронних мереж та прогнозування результатів, реалізовано інструментальні засоби у вигляді програмних модулів для навчання та прогнозування на основі хмарних сервісів.

Всі інструментальні засоби реалізовано мовою програмування Python. Провайдером хмарних сервісів є Amazon Web Services \cite{AWS}. Моделі глибоких нейронних мереж та методи іх навчання реалізовано на базі фреймворку автоматичного диференціювання Pytorch \cite{pytorch}. Відтворюваність результатів експериментів забезпечується використанням програмної високорівневої обгортки Catalyst \cite{catalyst}, яка дозволяє зберігання конфігурації експериментів у широко анотованих конфігураційних файлах. 

Інструментальні засоби навчання моделей розгорнуті за допомогою сервісу AWS EC2 \cite{ec2}, в той час як прогнозування результатів розгорнуто за допомогою AWS Sagemaker \cite{sagemaker}. 

Зберігання даних та артефактів навчання моделей (файли конфігурації та бінарні файли) зберігаються за допомогою сервісу AWS S3 \cite{s3}.

Сучасні нейронні мережі в цілому, та запропоновані їх моделі потребують високої кількості обчислювальних ресурсів в процесі навчання. Необхідною складовою обладнання для їх навчання є відеоприскорювачі загального призначення (\textit{англ.} General-Purpose Graphic Processing Unit - GPGPU). Економічно-вигідним є використання арендних відеоприскорювачів в <<хмарних сервісах>>, що потребує відповідної зміни парадигм проектування систем навчання. 

Протягом останніх років виник інтерес до запуску нейронних мереж на пограничних пристроях як до альтернативи роботи на віддалених серверах, наприклад, безпосередньо на камерах відеоспостереження, для зниження витрат на підтримку інфраструктури. 

Таким чином, створення такої архітектури, яка б дозволяла мати можливість зміни місць розташування сервісів навчання та прогнозування є актуальним.

Розроблена загальна структура інструментальних засобів зазначена на рисунку \ref{fig:architecture}.

\begin{figure}
	\centering
	\includegraphics[width=16cm]{general_arch.png}
	\caption{Розроблена архітектура інструментальних засобів}
	\label{fig:architecture}
\end{figure} 


Така композиція архітектури має можливість інтеграції в більшість систем автоматизованого скринінгу, а також спрощує написання клієнтських модулів.


\section{Випробування розробленого методу. Експерименти на синтетичних даних}

Для оцінки запропонованих методів в контрольованих умовах помилкових анотацій, проведено експерименти на згенерованих наборах даних, що були синтезовані за допомогою розробленої моделі наборів даних із частково-помилковими анотаціями. 

\textbf{При виконанні експериментів використовувалися наступні вихідні дані:}

В наведених нижче експериментах використовуються наступні \textbf{метрики}:

\begin{itemize}
	\item Метрика F1 для оцінки задачі класифікації;
	\item коефіцієнт Дайса для оцінки задачі сегментації;
	\item коефіцієнт роздільності внутрішніх представлень $K_{sep}$.
\end{itemize}

В експериментах поставлена задача багатокласової класифікації та семантичної сегментації, для отримання фінального значення метрик, вони усереднені по класах.

\paragraph{Кількісна оцінка роздільності внутрішніх представлень нейронної мережі}

Для оцінки роздільності внутрішніх представлень, використовується метод К-середніх. Оскільки в задачах класифікації та семантичної сегментації заздалегідь відома кількість класів, можна визначити необхідну кількість кластерів ознак у внутрішньому представленні нейронної мережі. 

Для набору даних над ознаками з внутрішнього представлення обчислюється кількість кластерів, що відповідає кількості класів в основній задачі. Після чого, обчислюється середня Евклідова відстань між центрами кластерів. Таким чином, більшій відстані між кластерами відповідає краща роздільність внутрішніх представлень. 

Також, для наочної демонстрації складу внутрішніх представлень, ознаки проектуються за допомогою алгоритму нелінійного відображення Uniform Manifold Approximation and Projection (UMAP) \cite{umap} на двомірну площину.

\paragraph{Структура нейронних мереж}
У всіх експериментах використана однакова структура нейронних мереж якщо не зазначено інакше.

\emph{Структура базової моделі}
Базова модель являє собою екземпляр архітектури UNet. В ролі енкодера використана архітектура нейронної мережі ResNet34, що ініціалізована вагами претренованої на наборі даних Imagenet нейронної мережі.

Декодер виконано відповідно до класичної архітектури UNet, що складається з п'яти стадій (рисунок \ref{fig:my_decoder_block_arch}). Кількість каналів в згортках стадій від найглибшої: 256, 128, 64, 32, 16. Функція активації декодера - ReLU. На кожній стадії використовується пакетна нормалізація ознак. Додаткові з'єднання від енкодера передаються за допомогою операції конкатенації. Функція активації останнього шару декодера - логістична сигмоїда. 

\emph{Структура запропонованої моделі}

Енкодер та декодер сегментації запропонованої моделі виконані відповідно до структури, описаної в розділі \ref{nn-arch}. При навчанні запропонованої моделі використовується обмежена функція втрат для задачі сегментації, а при прогнозуванні використовується метод об	єднання задач класифікації та сегментації.

\paragraph{Параметри експериментів}

\emph{Загальна процедура навчання}
Cкладається з одного циклу навчання та валідації, якщо не вказано інакше.

Використано наступні параметри навчання:
\begin{itemize}
	\item Розмір зображення: $224 \times 224$ пікселя
	\item Розмір пакету навчання: 32
	\item Кількість тренувальних зображень: 15000
	\item Кількість тестових зображень: 5000
	\item Кількість епох навчання: 20
	\item Оптимізатор: RAdam \cite{radam}
	\item Темп навчання: $10^{-3}$
	\item Коефіцієнт L2 регуляризації параметрів мережі: $10^{-4}$
	\item Закон зміни темпу навчання: косинус \cite{cosine_annealing}
\end{itemize}




\paragraph{Результати випробувань}
%юююю добавить описание чуть лучше
% добавить таблицу с описанием и таблицу с выводами

Експерименти виконано відповідно до задач автоматизованого скринінгу, для яких розроблено модель наборів даних, що описані в розділі \ref{lbl:model_image_analysis} (експерименти 1-5). 

Результати експериментів 6 та 7 дозволяють оцінити  стійкість запропонованого методу багатозадачного навчання нейронних мереж до різних рівнів помилок в анотаціях на простих та складних зображеннях.  

В експерименті 8 досліджено внесок окремих компонентів запропонованих методів багатозадачного навчання глибинних нейронних мереж в різних умовах. 

\paragraph{Експеримент 1}
Порівняння базового та запропонованого методів на простому наборі даних із достовірними анотаціями.
Параметри генерації набору даних зазначено в таблиці \ref{tab:experiment1}.

\qquad
\begin{center}	
	\captionof{table}{Параметри набору даних експеримента 1}
	\label{tab:experiment1}
	\begin{tabular}{ | c | c |}
		\hline
		Об'єкти & MNIST \\
		\hline
		Текстура фону & константна \\
		\hline
		Текстура об'єктів & константна \\
		\hline
		$P_e$ & 0 \\
		\hline
		$P_d$ & 0 \\
		\hline
		$N_{obj}$ & 10 \\
		\hline
		$S_{obj}$ & 36 \\ 
		\hline 
		$\Delta_{max}$ & 0.2 \\
		\hline
	\end{tabular}
\end{center}
\qquad

Результати експерименту наведено в таблиці \ref{tab:experiment1_results}.

\qquad
\begin{center}	
	\captionof{table}{Результати експеримента 1}
	\label{tab:experiment1_results}
	\begin{tabular}{ | l | c | c | c | }
		\hline
		Модель & Міра Дайса & F1-міра & $K_{sep}$ \\
		\hline\hline
		Базова модель & 0.86 & -  & 14.33 \\
		\hline
		Запропонований метод & 0.87 & 0.98 & 17.51 \\
		\hline
	\end{tabular}

\end{center}
\qquad
	
На рисунку \ref{fig:exp1_preds} зображено приклади прогнозів нейронної мережі для тестових зображень.

\begin{figure}
	\centering
	\includegraphics[width=12cm]{exp_results/exp1_preds.png}
	\caption{Прогнози нейронної мережі для тестового зображення}
	\label{fig:exp1_preds}
\end{figure}

На рисунках \ref{fig:exp1_umap_base} та \ref{fig:exp1_umap_prop} зображено UMAP-проекцію ознак останнього шару енкодера для набору тестових зображень.

\begin{figure}
	\centering
	\begin{minipage}{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{exp_results/exp1_base_umap.png}
		\captionsetup{justification=centering}
		\caption{UMAP ознак \newline базової моделі}
		\label{fig:exp1_umap_base}
	\end{minipage}\hfill
	\begin{minipage}{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{exp_results/exp1_prop_umap.png} % second figure itself
		\captionsetup{justification=centering}
		   
		\caption{UMAP ознак запропонованої моделі}
		\label{fig:exp1_umap_prop}
	\end{minipage}
\end{figure}













\paragraph{Експеримент 2}
Порівняння базового та запропонованого методів на простому наборі даних із частково-помилковими анотаціями.
Параметри генерації набору даних зазначено в таблиці \ref{tab:experiment2}.

\qquad
\begin{center}	
	\captionof{table}{Параметри набору даних експеримента }
	\label{tab:experiment2}
	\begin{tabular}{ | c | c |}
		\hline
		Об'єкти &  MNIST \\
		\hline
		Текстура фону &  константна \\
		\hline
		Текстура об'єктів &  константна \\
		\hline
		$P_e$ &  0.1 \\
		\hline
		$P_d$ &  0.25 \\
		\hline
		$N_{obj}$ & 10 \\
		\hline
		$S_{obj}$ & 36 \\ 
		\hline 
		$\Delta_{max}$ & 0.2 \\
		\hline
	\end{tabular}
\end{center}
\qquad

Результати експерименту наведено в таблиці \ref{tab:experiment2_results}.

\qquad
\begin{center}	
	\captionof{table}{Результати експеримента }
	\label{tab:experiment2_results}
	\begin{tabular}{ | l | c | c | c |}
		\hline
		Модель & Міра Дайса & F1-міра & $K_{sep}$ \\
		\hline\hline
		Базова модель & 0.81 & - & 12.10 \\
		\hline
		Запропонований метод & 0.91 & 0.93 & 15.73 \\
		\hline
	\end{tabular}
	
\end{center}
\qquad

На рисунку \ref{fig:exp2_preds} зображено приклади прогнозів нейронної мережі для тестових зображень.

\begin{figure}[H]
	\centering
	\includegraphics[width=14cm ]{exp_results/exp2_preds.png}
	\caption{Прогнози нейронної мережі для тестового зображення}
	\label{fig:exp2_preds}
\end{figure}

На рисунках \ref{fig:exp2_umap_base} та \ref{fig:exp2_umap_prop} зображено UMAP-проекцію ознак останнього шару енкодера для набору тестових зображень.

\begin{figure}
	\centering
	\begin{minipage}{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{exp_results/exp2_base_umap.png}
		\captionsetup{justification=centering}
		\caption{UMAP ознак \newline базової моделі}
		\label{fig:exp2_umap_base}
	\end{minipage}\hfill
	\begin{minipage}{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{exp_results/exp2_prop_umap.png}
		\captionsetup{justification=centering}
		
		\caption{UMAP ознак запропонованої моделі}
		\label{fig:exp2_umap_prop}
	\end{minipage}
\end{figure}

В умовах навчання за частково-помилковими анотаціями, запропонований метод дає більш впевнені прогнози, також зберігаючи тонкі лінії, що порушуються при виконанні операції ерозії над розміткою.








\paragraph{Експеримент 3}
Порівняння базового та запропонованого методів на простому наборі даних з ускладненими об'єктами та частково-помилковими анотаціями.
Параметри генерації набору даних зазначено в таблиці \ref{tab:experiment3}.

\qquad
\begin{center}	
	\captionof{table}{Параметри набору даних експеримента }
	\label{tab:experiment3}
	\begin{tabular}{ | c | c |}
		\hline
		Об'єкти &  FashionMNIST \\
		\hline
		Текстура фону &  константна \\
		\hline
		Текстура об'єктів &  константна \\
		\hline
		$P_e$ &  0.1 \\
		\hline
		$P_d$ &  0.25 \\
		\hline
		$N_{obj}$ & 10 \\
		\hline
		$S_{obj}$ & 36 \\ 
		\hline 
		$\Delta_{max}$ & 0.2 \\
		\hline
	\end{tabular}
\end{center}
\qquad

Результати експерименту наведено в таблиці \ref{tab:experiment3_results}.

\qquad
\begin{center}	
	\captionof{table}{Результати експеримента }
	\label{tab:experiment3_results}
	\begin{tabular}{ | l | c | c | c |}
		\hline
		Модель & Міра Дайса & F1-міра & $K_{sep}$ \\
		\hline\hline
		Базова модель & 0.83 & - & 27.49 \\
		\hline
		Запропонований метод & 0.87 & 0.88 & 32.12 \\
		\hline
	\end{tabular}
	
\end{center}
\qquad

На рисунку \ref{fig:exp3_preds} зображено приклади прогнозів нейронної мережі для тестових зображень.

\begin{figure}
	\centering
	\includegraphics[width=14cm ]{exp_results/exp3_preds.png}
	\caption{Прогнози нейронної мережі для тестового зображення}
	\label{fig:exp3_preds}
\end{figure}

На рисунках \ref{fig:exp3_umap_base} та \ref{fig:exp3_umap_prop} зображено UMAP-проекцію ознак останнього шару енкодера для набору тестових зображень.

\begin{figure}
	\centering
	\begin{minipage}{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{exp_results/exp3_base_umap.png}
		\captionsetup{justification=centering}
		\caption{UMAP ознак \newline базової моделі}
		\label{fig:exp3_umap_base}
	\end{minipage}\hfill
	\begin{minipage}{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{exp_results/exp3_prop_umap.png}
		\captionsetup{justification=centering}
		
		\caption{UMAP ознак запропонованої моделі}
		\label{fig:exp3_umap_prop}
	\end{minipage}
\end{figure}

Як і в попередньому експерименті, в умовах частково-помилкових анотацій, запропонований метод дає більш впевнені прогнози, також зберігаючи більше малих деталей.





\paragraph{Експеримент 4}
Порівняння базового та запропонованого методів на складному наборі даних з простими  об'єктами та частково-помилковими анотаціями.
Параметри генерації набору даних зазначено в таблиці \ref{tab:experiment4}.

\qquad
\begin{center}	
	\captionof{table}{Параметри набору даних експеримента }
	\label{tab:experiment4}
	\begin{tabular}{ | c | c |}
		\hline
		Об'єкти &  MNIST \\
		\hline
		Текстура фону &  Imagenette \\
		\hline
		Текстура об'єктів &  Imagenette \\
		\hline
		$P_e$ &  0.1 \\
		\hline
		$P_d$ &  0.25 \\
		\hline
		$N_{obj}$ & 10 \\
		\hline
		$S_{obj}$ & 36 \\ 
		\hline 
		$\Delta_{max}$ & 0.2 \\
		\hline
	\end{tabular}
\end{center}
\qquad

Результати експерименту наведено в таблиці \ref{tab:experiment4_results}.

\qquad
\begin{center}	
	\captionof{table}{Результати експеримента }
	\label{tab:experiment4_results}
	\begin{tabular}{ | l | c | c | c |}
		\hline
		Модель & Міра Дайса & F1-міра & $K_{sep}$ \\
		\hline\hline
		Базова модель & 0.69 & - & 15.26 \\
		\hline
		Запропонований метод & 0.72 & 0.75 & 18.90 \\
		\hline
	\end{tabular}
	
\end{center}
\qquad

На рисунку \ref{fig:exp4_preds} зображено приклади прогнозів нейронної мережі для тестових зображень.

\begin{figure}
	\centering
	\includegraphics[width=14cm ]{exp_results/exp4_preds.png}
	\caption{Прогнози нейронної мережі для тестового зображення}
	\label{fig:exp4_preds}
\end{figure}

На рисунках \ref{fig:exp4_umap_base} та \ref{fig:exp4_umap_prop} зображено UMAP-проекцію ознак останнього шару енкодера для набору тестових зображень.

\begin{figure}
	\centering
	\begin{minipage}{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{exp_results/exp4_base_umap.png}
		\captionsetup{justification=centering}
		\caption{UMAP ознак \newline базової моделі}
		\label{fig:exp4_umap_base}
	\end{minipage}\hfill
	\begin{minipage}{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{exp_results/exp4_prop_umap.png}
		\captionsetup{justification=centering}
		
		\caption{UMAP ознак запропонованої моделі}
		\label{fig:exp4_umap_prop}
	\end{minipage}
\end{figure}

Як і в попередньому експерименті, в умовах навчання з частково-помилковими анотаціями, запропонований метод дає більш впевнені прогнози, також зберігаючи більше малих деталей. Однак, внутрішні представлення мають гіршу роздільність через більш складний тип вхідних даних.







\paragraph{Експеримент 5}
Порівняння базового та запропонованого методів на складному наборі даних з ускладненими об'єктами та частково-помилковими анотаціями.
Параметри генерації набору даних зазначено в таблиці \ref{tab:experiment5}.

\qquad
\begin{center}	
	\captionof{table}{Параметри набору даних експеримента }
	\label{tab:experiment5}
	\begin{tabular}{ | c | c |}
		\hline
		Об'єкти &  FashionMNIST \\
		\hline
		Текстура фону &  Imagenette \\
		\hline
		Текстура об'єктів &  Imagenette \\
		\hline
		$P_e$ &  0.1 \\
		\hline
		$P_d$ &  0.25 \\
		\hline
		$N_{obj}$ & 10 \\
		\hline
		$S_{obj}$ & 36 \\ 
		\hline 
		$\Delta_{max}$ & 0.2 \\
		\hline
	\end{tabular}
\end{center}
\qquad

Результати експерименту наведено в таблиці \ref{tab:experiment5_results}.

\qquad
\begin{center}	
	\captionof{table}{Результати експеримента }
	\label{tab:experiment5_results}
	\begin{tabular}{ | l | c | c | c |}
		\hline
		Модель & Міра Дайса & F1-міра & $K_{sep}$ \\
		\hline\hline
		Базова модель & 0.70 & - & 7.02 \\
		\hline
		Запропонований метод & 0.75 & 0.78 & 10.6 \\
		\hline
	\end{tabular}
	
\end{center}
\qquad

На рисунку \ref{fig:exp5_preds} зображено приклади прогнозів нейронної мережі для тестових зображень.

\begin{figure}
	\centering
	\includegraphics[width=14cm ]{exp_results/exp5_preds.png}
	\caption{Прогнози нейронної мережі для тестового зображення}
	\label{fig:exp5_preds}
\end{figure}

На рисунках \ref{fig:exp5_umap_base} та \ref{fig:exp5_umap_prop} зображено UMAP-проекцію ознак останнього шару енкодера для набору тестових зображень.

\begin{figure}
	\centering
	\begin{minipage}{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{exp_results/exp5_base_umap.png}
		\captionsetup{justification=centering}
		\caption{UMAP ознак \newline базової моделі}
		\label{fig:exp5_umap_base}
	\end{minipage}\hfill
	\begin{minipage}{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{exp_results/exp5_prop_umap.png}
		\captionsetup{justification=centering}
		
		\caption{UMAP ознак запропонованої моделі}
		\label{fig:exp5_umap_prop}
	\end{minipage}
\end{figure}

Як і в попередньому експерименті, в умовах помилок в анотаціях, запропонований метод дає більш впевнені прогнози, також зберігаючи більше малих деталей. Однак, внутрішні представлення мають гіршу роздільність через більш складний тип вхідних даних.


\paragraph{Експеримент 6}
Стійкість методів до різних рівнів помилок в анотаціях на простих даних.

Для оцінки стійкості базового та запропонованого методів до відсотку помилок в анотаціях, проведено серію експериментів зі зміною вірогідності помилки для кожного з об'єктів в наборі даних. 

Результати експерименту наведено в таблиці \ref{tab:experiment_com}

\qquad
\begin{center}	
	\captionof{table}{Порівняння стійкості моделей до помилкових анотацій}
	\label{tab:experiment_com}
	\begin{tabular}{ | l | c | c | c |}
		\hline
		$P_e$ & $P_d$ & Міра Дайса Базовий метод & Міра Дайса  Запропонований метод \\
		\hline\hline
		0.1 & 0.1 & 0.84 & 0.96 \\
		\hline
		0.1 & 0.25 & 0.81 & 0.91 \\
		\hline
		0.25 & 0.1 & 0.65 & 0.83 \\
		\hline
		0.5 & 0.25 & 0.51 & 0.62 \\
		\hline
		0.25 & 0.5 & 0.57 & 0.69 \\
		\hline
		0.5 & 0.5 & 0.3 & 0.47 \\
		\hline 
		0.75 & 0.75 & 0.12 & 0.23 \\
		\hline
	\end{tabular}
\end{center}
\qquad

З таблиці видно, що запропонований метод є більш стійким до більшого відсотку помилкових анотацій. Також, як запропонований, так і базовий методи менш стійкі до підвищеної ймовірності ерозії.

\paragraph{Експеримент 7}
Стійкість методів до різних рівнів помилок в анотаціях на складних даних.

Для перевірки стійкості до помилок в анотаціях в умовах наближених до реальних, попередній експеримент проведено з використанням фону та текстур об'єктів з набору даних Imagenette. Результати експерименту наведено в таблиці \ref{tab:experiment_com_imagenette}.


\qquad
\begin{center}	
	\captionof{table}{Порівняння стійкості моделей до помилок в анотаціях}
	\label{tab:experiment_com_imagenette}
	\begin{tabular}{ | l | c | c | c |}
		\hline
		$P_e$ & $P_d$ & Міра Дайса Базовий метод & Міра Дайса  Запропонований метод \\
		\hline\hline
		0.1 & 0.1  & 0.72 & 0.78 \\
		\hline
		0.1 & 0.25 & 0.70 & 0.75 \\
		\hline
		0.25 & 0.1 & 0.61 & 0.69 \\
		\hline
		0.5 & 0.25 & 0.48 & 0.53 \\
		\hline
		0.25 & 0.5 & 0.55 & 0.60 \\
		\hline
		0.5 & 0.5 & 0.21 & 0.41 \\
		\hline 
		0.75 & 0.75 & 0.08 & 0.15 \\
		\hline
	\end{tabular}
\end{center}
\qquad

Результати експерименту збігаються з результатами попереднього експерименту, хоча мають тенденцію до зменшення середнього значення метрики через підвищену складність даних. 


\paragraph{Експеримент 8}
\emph{Дослідження внеску окремих компонентів.} 
Параметри генерації набору даних зазначено в таблиці \ref{tab:experiment_ablations}.

\qquad
\begin{center}	
	\captionof{table}{Параметри набору даних для проведення дослідження внеску окремих компонентів}
	\label{tab:experiment_ablations}
	\begin{tabular}{ | c | c |}
		\hline
		Текстура фону & Imagenette\\
		\hline
		Текстура об'єктів & Imagenette \\
		\hline
		$P_e$ & 0.2 \\
		\hline
		$P_d$ & 0.2 \\
		\hline
		$N_{obj}$ & 10 \\
		\hline
		$S_{obj}$ & 36 \\ 
		\hline 
		$\Delta_{max}$ & 0.2 \\
		\hline
	\end{tabular}
\end{center}
\qquad

В таблиці \ref{tab:ablations_results} наведено значення міри Дайса в задачі семантичної сегментації при послідовному додаванні складових частин запропонованого метода до базової моделі.  Використані скорочення:

\begin{itemize}
	\item MN - MNIST
	\item FM - FashionMNIST
	\item IN - ImageNette
	\item C - константний колір
\end{itemize}

Використано наступний порядок кодів в шифрі: 

\begin{enumerate}
	\item Набір даних, з якого взято об'єкти
	\item Набір даних, з якого взято текстури фону
	\item Набір даних, з якого взято текстури об'єктів
\end{enumerate}

\qquad
\begin{center}	
	\captionof{table}{Дослідження внеску окремих компонентів}
	\label{tab:ablations_results}
	\begin{tabular}{ | l | c | c | c | c |}
		\hline
		Змінна 		  			   & MN/C/C & FM/C/C & MN/IN/IN & FM/IN/IN \\
		\hline\hline
		Базова модель 			   & 0.81 	& 0.83 	 & 0.69 	& 0.70 \\
		\hline
		 + декодер класифікації    & 0.83 	& 0.84   & 0.69 	& 0.71 \\
		\hline
		 + обмеження функції втрат & 0.88 	& 0.86   & 0.71 	& 0.74 \\
		\hline
		 + комбінація прогнозів    & 0.91 	& 0.87   & 0.72 	& 0.75 \\
		\hline
	\end{tabular}
\end{center}
\qquad

З зазначеної таблиці видно, що найбільший приріст дають обмеження функції втрат та комбінація прогнозів, хоча для отримання повного ефекту необхідні всі складові частини запропонованого методу. Також, більш складні набори даних зменшують відносний приріст метрик, що є очікуваним через потребу збільшення кількості параметрів в нейронній мережі для можливості вивчення ускладнених представлень.































\section{Випробування розробленого методу. Експерименти на реальних даних}





\subsection{Класифікація та сегментація формацій хмар}
\paragraph{Опис набору даних Understanding Clouds from Satellite Images}
Набір даних Understanding Clouds from Satellite Images (UCSID) складається з 10000 RGB зображень, зроблених з двох супутників TERRA та AQUA, що знаходяться на полярній орбіті [6]. Кожен з цих супутників проходить над певну областю один раз на день. Через обмежене поле зору камер, встановлених на цих супутниках, кожне зображення зшито з двох супутників, що знаходяться над однією й тою самою областю одночасно, але на різних орбітах. Решта зображення, для якої не було знято даних під час прольоту супутників (між орбітами) заповнена чорним кольором. Оскільки зображення підлягають компресії, є артефакти стиснення, та чорний колір має деякі незначні аномалії.

На знімках є регіони, які містять певні хмарні утворення, та помічені дослідниками відповідно: Риба, Квітка, Гравій, Цукор (\textit{англ}. Fish, Flower, Gravel, Sugar). Кожне зображення має принаймні одне хмарне утворення і може містити до всіх чотирьох одночасно.

Розмітка для цих регіонів була створена під час краудсорсингу в Інституті метеорології імені Макса Планка в Гамбурзі, Німеччина, та Laboratoire de meterologie Dynamique у Парижі, Франція. Команда з 68 вчених виявила ділянки з хмарами на кожному зображенні, і кожне зображення було розмічене, в середньому, трьома різними вченими. Кожен вчений мав виділити хмари за допомогою прямокутних областей на власний розсуд. Основна розмітка була створена об’єднанням областей, що були розмічені всіма вченими для цього зображення, після видалення чорної смуги з цих областей [7].

Через те, як був зібраний UCSID, він має значну кількість помилково-анотованих пікселів масках для хмар. Оскільки маски складаються з прямокутників, які повністю перекривають хмару, існує багато пікселів, які позначені як хмари, але, насправді, відповідають фону. Також, не всі хмари позначені масками. Через об'єднання масок від різних анотаторів, класи можуть суттєво перетинатися - один і той самий піксель може бути помічений декількома класами, включаючи випадки, коли всі чотири класи присвоюються одним і тим самим пікселям.

Усі зображення мають вихідну роздільну здатність 2100x1400 пікселів. Більшість зображень містять більше ніж один клас хмар. Немає зображень без хмар. Розподіл класів хмар на зображеннях показано на рисунку \ref{fig:clouds-cooccurerence}.

\begin{figure}[H]
	\centering
	\includegraphics[width=8cm]{clouds-cooccurerence.png}
	\caption{Частота зустрічі декількох типів хмар на одному зобораженні}
	\label{fig:clouds-cooccurerence}
\end{figure} 


Різні типи хмар зазвичай зустрічаються разом, розподіл комбінацій різних типів хмар зазначено на рисунку.
UCSID розділено на 5546 тренувальних, та 3698 валідаційних зображень. Крім того, немає доступу до міток валідаційного набору даних. Значення метрики можливо отримати через систему валідації.

До розподілу міток класів в наборі даних не було виконано змін (недодискретизація, передискретизація тощо). Для отримання більш стабільного значення метрик в умовах помилок в тестових анотаціях, оцінювання якості моделей виконано за допомогою k-кратної перехресної перевірки \cite{kfold}. 

\paragraph{Процедура навчання}

Тренування та прогнозування проводиться на зменшених версіях оригінальних зображень. Загальні параметри навчання: 

\begin{itemize}
	\item Розмір зображення: $350 \times 525$ пікселя
	\item Розмір пакету навчання: 64
	\item Кількість тренувальних зображень: 5546
	\item Кількість тестових зображень: 3698
	\item Кількість епох навчання: 50
	\item Оптимізатор: Adam
	\item Темп навчання: $10^{-4}$
	\item Коефіцієнт L2 регуляризації параметрів мережі: $10^{-4}$
	\item Закон зміни темпу навчання: косинус
	\item $k$ : 5
\end{itemize}


\emph{Структура базової моделі}
Базова модель являє собою екземпляр архітектури UNet. В ролі енкодера використана архітектура нейронної мережі ResNet50, що ініціалізована вагами претренованої на наборі даних Imagenet нейронної мережі.

Декодер виконано відповідно до класичної архітектури UNet, що складається з п'яти стадій. Кількість каналів в згортках стадій від найглибшої: 256, 128, 64, 32, 16. Функція активації декодера - ReLU. На кожній стадії використовується пакетна нормалізація ознак. Додаткові з'єднання від енкодера передаються за допомогою операції конкатенації. Функція активації останнього шару декодера - логістична сигмоїда. 

\emph{Структура запропонованої моделі}

Енкодер та декодер сегментації запропонованої моделі виконані відповідно до структури, описаної в розділі \ref{nn-arch}. При навчанні запропонованої моделі використовується обмежена функція втрат для задачі сегментації, а при прогнозуванні використовується метод об'єднання задач класифікації та сегментації.



\paragraph{Результати експерименту}

Чисельні результати експерименту зазначено в таблиці \ref{tab:clouds_experiment_results}.  

\qquad
\begin{center}	
	\captionof{table}{Результати експеримента }
	\label{tab:clouds_experiment_results}
	\begin{tabular}{ | l | c | c |}
		\hline
		Модель & Міра Дайса & F1-міра \\
		\hline\hline
		Базова модель & 0.56 $\pm$ 0.03 & - \\
		\hline
		Запропонований метод & 0.63 $\pm$ 0.02 & 0.70 $\pm$ 0.01 \\
		\hline
	\end{tabular}
	
\end{center}
\qquad

Приклад зображення з тестового набору даних з вихідною розміткою та прогнозом нейронної мережі зображено на рисунку \ref{fig:clouds-preds}.

\begin{figure}
	\centering
	\includegraphics[width=12cm]{clouds-preds.png}
	\caption{Оригінальна розмітка (контури) та прогнози нейронної мережі (заливка)}
	\label{fig:clouds-preds}
\end{figure} 












\subsection{Класифікація стадії осередків діабетичної ретинопатії}
В даному експерименті розглянуто можливість переносу підходу із задачі сегментації на задачу класифікації. Так, в ролі похідних задач до задачі класифікації використані задачі лінійної регресії мітки класу, а також порядкової регресії, що відповідає специфіці задачі \cite{ordinal_regression}.
  
\paragraph{Опис наборів даних}
Використані в цьому експерименті зображення, були взяті з декількох наборів даних. Для претренування нейронних мереж було використано відкритий набір даних від Kaggle: “Diabetic Retinopathy Detection Challenge 2015” {dr2015}.

Цей набір даних є найбільшим із загальнодоступних. Він складається з 35126 фотографій очного дна для лівого та правого ока американських громадян, з розміченими стадіями діабетичної ретинопатії за стандартним протоколом:
\begin{itemize}
	\item Відсутність діабетичної ретинопатії (мітка 0);
	\item легка діабетична ретинопатія (мітка 1);
	\item помірна діабетична ретинопатія (мітка 2);
	\item важка діабетична ретинопатія (мітка 3);
	\item проліферативна діабетична ретинопатія (мітка 4).
\end{itemize}

Крім того, були використані менші набори даних: набір зображень індійської діабетичної ретинопатії (IDRiD) \cite{idrid}, з якого використано 413 фотографій очного дна, та MESSIDOR (Методи оцінки методів сегментації та індексації в області офтальмології сітківки) \cite{messidor}, з якого використано 1200 фотографій очного дна. Оскільки розмітка оригінального набору даних MESSIDOR відрізняється від інших наборів даних, ми використали версію, яку група офтальмологів \cite{messidor_relabeled} помаркувала відповідно до стандартного протоколу. 

Усі зазначені набори даних мають однаковий розподіл міток класів, що є фундаментальною властивістю для цієї задачі. 

Оцінка проводиться на наборі даних Kaggle APTOS2019 \cite{aptos2019}, дослідники мають доступ лише до тренувальної та валідаційної частин. Повний набір даних складається з 18590 фотографій очного дна, які розділені на набори з 3662 тренувальних, 1928 валідаційних та 13000 тестових зображень, що були розділені організаторами змагань Kaggle.

\paragraph{Процедура навчання}

Тренування та прогнозування проводиться на зменшених версіях оригінальних зображень. Загальні параметри навчання: 

\begin{itemize}
	\item Розмір зображення: $380 \times 380$ пікселя
	\item Розмір пакету навчання: 32
	\item Кількість тренувальних зображень: 5275
	\item Кількість тестових зображень: 1928
	\item Кількість епох навчання: 75
	\item Оптимізатор: RAdam
	\item Темп навчання: $10^{-4}$
	\item Коефіцієнт L2 регуляризації параметрів мережі: $10^{-4}$
	\item Закон зміни темпу навчання: косинус
	\item $k$ : 5
\end{itemize}


\emph{Структура базової моделі}
Базова модель являє собою екземпляр архітектури ResNet. В ролі енкодера використана архітектура нейронної мережі ResNeXt50, що ініціалізована вагами претренованої на наборі даних Imagenet нейронної мережі.

Декодер класифікації являє собою два лінійних шари, функція активації - ReLU. Функція активації останнього шару декодера - логістична сигмоїда. 

\emph{Структура запропонованої моделі}

Енкодер та декодери запропонованої моделі виконані відповідно до структури, описаної в розділі \ref{nn-arch}. При навчанні запропонованої моделі використовується обмежена функція втрат для задачі класифікації, а при прогнозуванні використовується запропонований метод об'єднання задач.

\emph{Комбінування результатів декількох задач}
На етапі після основного навчання, для кожної з моделей, навчається модель лінійної регресії з виходів декодерів в єдине значення.

Лінійна регресія навчається після основного навчання, оскільки в іншому випадку, сходиться до неоптимальних локальних мінімумів з вагами двох декодерів, близьких до нуля. Ці нульові ваги запобігають оновленню відповідних ваг декодерів і, відповідно, запобігають навчанню.
Початкові ваги для кожного з виходів декодерів були встановлені рівними 1/3, а потім тренувались протягом п’яти епох, щоб мінімізувати середньоквадратичну функцію помилки.


\emph{Ініціалізація нейронної мережі}
Відпочатку, енкодер ініціалізується параметрами нейронної мережі, що була натренована на наборі даних ImageNet. Параметри декодерів ініціалізуються випадково (ініціалізація Хе). 

Природні особливості діабетичної ретинопатії узгоджуються між різними людьми і не залежать від набору даних. Крім того, різні набори даних збираються на різному обладнанні. Включення цих знань у модель підвищує її здатність до узагальнення та підвищує важливість природних ознак за рахунок зменшення чутливості до особливостей обладнання.

Для попереднього навчання, ініціалізована нейронна мережа навчається на протязі 20 епох на наборі даних DRDC2015 за допомогою стохастичного градієнтного спуску. Основна мета попереднього навчання - створити ініціалізацію параметрів на розподілі даних, що є близьким до цільового. Після попереднього навчання, параметри нейронної мережі використовуються як ініціалізація для основного навчання.

Під час попереднього навчання, кожен декодер мінімізує свою функцію втрат: перехресну ентропію для класифікаційного декодера, бінарну перехресну ентропію для декодера порядкової регресії та середню абсолютну похибку для декодера регресії.

Основне тренування проводиться на наборах даних APTOS2019, IDRID та MESSIDOR разом. Починаючи з ваг, отриманих на етапі попереднього тренування, виконується 5-кратна перехресна перевірка та оцінка моделі на відкладеному наборі даних. На цьому етапі функції втрат для декодерів змінено: фокальна функція втрат \cite{focalloss} для класифікаційного декодера, бінарна фокальна функція втрат \cite{focalloss}  для декодера порядкової регресії та середньоквадратична помилка для декодера регресії.


\paragraph{Результати експерименту}

Чисельні результати експерименту зазначено в таблиці \ref{tab:eyes_experiment_results}.  

\qquad
\begin{center}	
	\captionof{table}{Результати експеримента }
	\label{tab:eyes_experiment_results}
	\begin{tabular}{ | l | c |}
		\hline
		Модель &  F1-міра \\
		\hline\hline
		Базова модель & 0.68 $\pm$ 0.05 \\
		\hline
		Запропонований метод & 0.79 $\pm$ 0.06 \\
		\hline
	\end{tabular}
	
\end{center}
\qquad

















\subsection{Класифікація раку шкіри та локалізація родимок}

Метою даного експерименту є тестування запропонованого методу локалізації важливих для класифікації ознак в умовах відсутності розмітки сегментації.

\paragraph{Опис набору даних SIIM-ISIC Melanoma Classification}
Дані зображень, використані в цьому дослідженні, були взяті з декількох наборів даних з однаковою структурою: SIIM\&ISIC з 2017, 2018, 2019 та 2020 років. Ці набори даних були створені Міжнародною співпрацею з обробки зображень шкіри (\textit{англ}. International Skin Imaging Collaboration - ISIC), а зображення отримані з наступних джерел:
\begin{itemize}
	\item лікарня Клінік де Барселона;
	\item Віденський медичний університет;
	\item Центр раку Меморіал Слоун Кеттерінг;
	\item Австралійський інститут меланоми;
	\item Квінслендський університет;
	\item Афінська медична школа.
\end{itemize}

Загалом, ці набори даних складаються із приблизно 50000 RGB-зображень, з яких близько 3000 мають зображення злоякісних уражень. Набір даних містить 434 повторюваних зображення. Окрім даних про зображення, були надані метадані про пацієнтів. Один пацієнт має декілька зображень різних родинок.

Зображення та метадані надані у форматі DICOM, який є загальновживаним форматом даних медичних зображень. Крім того, набір даних доступний у форматі JPEG із розмірами зображень, змінених до 1024x1024. Метадані також надаються за межами формату DICOM, у файлах CSV \cite{kaggle-melanoma-data}.

Набір даних має високий дисбаланс класів. Розподіл діагнозів показано на рисунку \ref{fig:melanoma-hist}. 


\begin{figure}
	\centering
	\includegraphics[width=12cm]{melanoma_class_balance.png}
	\caption{Розподіл класів в наборі даних SIIM-ISIC Melanoma Classification}
	\label{fig:melanoma-hist}
\end{figure} 

Для значень unknown в полі diagnosis, автори набору даних гарантують, що новоутворення не є злоякісним \cite{kaggle-melanoma-data}.


\paragraph{Процедура навчання}

Тренування та прогнозування проводиться на зменшених версіях оригінальних зображень. Загальні параметри навчання: 

\begin{itemize}
	\item Розмір зображення: $512 \times 512$ пікселів
	\item Розмір пакету навчання: 64
	\item Кількість тренувальних зображень: 25000
	\item Кількість тестових зображень: 5000
	\item Кількість епох навчання: 50
	\item Оптимізатор: Adam
	\item Темп навчання: $10^{-4}$
	\item Коефіцієнт L2 регуляризації параметрів мережі: $10^{-4}$
	\item Закон зміни темпу навчання: косинус
	\item $k$ : 5
\end{itemize}


\emph{Структура базової моделі}
Базова модель являє собою екземпляр архітектури ResNet. В ролі енкодера використана архітектура нейронної мережі ResNet50, що ініціалізована вагами претренованої на наборі даних Imagenet нейронної мережі.

Декодер класифікації являє собою два лінійних шари, функція активації - ReLU. Функція активації останнього шару декодера - логістична сигмоїда. 

\emph{Структура запропонованої моделі}

Енкодер та декодери запропонованої моделі виконані відповідно до структури, описаної в розділі \ref{nn-arch}. Для спрощення задачі локалізації, декодер сегментації має менше стадій та виводить карту уваги в меншій роздільній здатності, ніж вхідне зображення. 

\emph{Процедура навчання}
Процедури навчання і прогнозування відповідають запропонованому методу напіватоматичного навчання задачі локалізації, що описаний в розділі \ref{unsup-method}. 


\paragraph{Результати експерименту}

Чисельні результати експерименту зазначено в таблиці \ref{tab:skin_experiment_results}.  

\qquad
\begin{center}	
	\captionof{table}{Результати експеримента }
	\label{tab:skin_experiment_results}
	\begin{tabular}{ | l | c |}
		\hline
		Модель &  F1-міра \\
		\hline\hline
		Базова модель & 0.83 $\pm$ 0.01 \\
		\hline
		Запропонований метод & 0.86 $\pm$ 0.01 \\
		\hline
	\end{tabular}
	
\end{center}
\qquad

Приклад локалізації нейронною мережею зображено на рисунку \ref{fig:exp_melanoma_benign}.

\begin{figure}
	\centering
	\includegraphics[width=12cm]{exp_melanoma_benign.png}
	\caption{Приклад напівавтоматичної локалізації родинок}
	\label{fig:exp_melanoma_benign}
\end{figure} 




















\section{Висновки до четвертого розділу}

У четвертому розділі розроблені інструментальні засоби, що реалізують запропоновані рішення. Проведено випробування розробленого методу в рамках експериментів як на синтетичних даних, що були згенеровані за допомогою запропонованої моделі, а також експерименти в реальних задачах: скринінг діабетичної ретинопатії, скринінг меланоми, та скринінг хмарних утворень.

В результаті експериментів показано переваги запропонованих багатозадачних нейронних мереж та методів їх навчання над базовими версіями. Проведено дослідження впливу відсотку помилкових анотацій на результати навчання, виявлено підвищення достовірності при використанні запропонованих методів для різних відсотків помилок в анотаціях. 

Проведено аналіз внеску окремих компонентів запропонованих моделей нейронних і методів їх навчання, показано їх позитивний вплив на достовірність прогнозів як окремо, так і в цілому.

Для задачі автоматизованого скринінгу при сегментації патернів організації хмар на супутникових знімках (в рамках проекту “Understanding Clouds from Satellite Images” на платформі для змагань з наук про дані Kaggle) було використано запропоновані моделі нейронних мереж, а також методи їх навчання та прогнозування результатів. Підвищення достовірності (міра Дайса) відносно базової моделі склало 3.9\%. 

Для задачі автоматизованого скринінгу при класифікації стадій діабетичної ретинопатії (в рамках проекту “APTOS 2019 Blindness Detection” на платформі для змагань з наук про дані Kaggle) було використано запропоновані методи багатозадачного навчання та прогнозування результатів. Підвищення достовірності (F1-міра) відносно базової моделі склало 2.1\%.

Для задачі розпізнавання уражень шкіри при скринінгу меланоми (у рамках проекту SIIM-ISIC Melanoma Classification на платформі для змагань з наук про дані Kaggle) було використано запропонований локалізації важливих для класифікації ознак зображення. Використання запропонованого методу дозволило спростити процес контролю навчання нейронних мереж, що допомогло попередити перенавчання і підвищити достовірність класифікації на 3.5\%.

В процесі порівняльного аналізу результатів запропонованих та базових моделей і методів встановлено перевагу над базовими моделями на 2-8\%

