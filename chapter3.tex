\chapter{Методи поєднання задач глибинного багатозадачного навчання}
Використання комбінації декількох задач машинного навчання може сприяти вивченню кращих наборів ознак, та підвищити точність роботи нейронних мереж. Також, можливе сумісне використання прогнозів декількох задач для уточнення кожного з окремих прогнозів, так і побудови нових. 


% 10 страниц ------------------------------------------------------------------------
\section{Метод багатозадачного навчання ШНМ в умовах частково помилкової розмітки семантичної сегментації}

В умовах частково-помилкової розмітки даних виникає потреба зменшення впливу неправильно розмічених прикладів на процес навчання, та їх ефективна фільтрація. Часто на одному зображенні можуть бути розташовані як коректно-розмічені, так і некоректно-розмічені об'єкти. Для підвищення точності навчання нейронних мереж в таких умовах, запропоновано використати метод багатозадачного навчання з використанням похідної більш загальної задачі.

\subsection{Генерація похідної задачі до задачі семантичної сегментації}


\textcolor{red}{ВОДУ СЮДА}

Семантично-близькими називають задачі, що мають однакові вхідні дані, та пов'язані вихідні дані.

На відміну від \cite{arxiv:1412.0069}, що спирається на вивчення більш детальних семантично-близьких задач, в розробленому методі використання більш точних даних, для загальніших задач дозволяє покращити роздільність внутрішніх представлень нейронної мережі, що, в свою чергу, покращує результати на вихідній задачі. Також, оскільки задачі є семантично близькими, не відбувається конфлікту градієнтів, що є типовим при навчанні семантично-різнорідних задач \cite{gradient_conflict}.

Оскільки задача семантичної сегментації може бути розглянута як задача піксельної класифікації, можна розглядати задачу класифікації всього зображення як більш загальну до неї. В такому контексті, класифікація буде окремим випадком навчання за набором зразків \cite{multiinstance}: замість розмітки кожного з об'єктів для всіх класів на зображенні, зображення являє собою мішок з одним, чи декількома об'єктами та відповідним маркуванням, чи є об'єкти заданих класів на ньому.

Попередній аналіз показав, що неточна розмітка в задачах сегментації полягає в наявності зайвих, або у відсутності деяких розмічених пікселів, або об'єктів. Наявність такої неточної розмітки дозволяє створити на її основі точну розмітку для класифікації.

Нехай для зображення $x \in \mathcal{R}^{3 \times H \times W}$ існує маска сегментації $y_s \in \mathcal{R}^{C \times H \times W}$ де $C$ - кількість класів, а $H$ та $W$ висота та ширина зображення відповідно. Якщо в масці сегментації є хоча б один розмічений об'єкт класу $с$, встановлюється мітка відповідного класу $y_c \in (0, 1)^C$ в розмітці задачі класифікації:

\begin{equation*}
	y_c = t < \sum_{i}^{H} \sum_{j}^{W} y_{s_{ij}}
\end{equation*}

де $t$ - поріг мінімального розміру об'єкта в пікселях

Згенерована таким чином задача класифікації має меншу ймовірність хибної розмітки.

\subsection{Автоматична фільтрація помилкової розмітки}
Маючи велику кількість параметрів, сучасні нейронні мережі здатні до запам'ятовування тренувального набору даних замість вивчення корисних ознак для узагальнення на інші набори даних (перенавчання). В умовах наявності помилкової розмітки в тренувальному наборі даних, нейронні мережі схильні до вивчення і помилок розмітки на протязі навчання. 

Традиційні методи запобігання перенавчанню, такі як аугментація даних, регуляризація ваг мережі, та завчасна зупинка навчання хоча і показують покращені результати, але можуть виявитися недостатніми в умовах великої ймовірності помилок в навчальних даних. Також, вони можуть погіршити якість навчання через зменшення ємності нейронної мережі, або, при надмірному використанні, можуть спонукати нейронну мережу акцентувати увагу на текстурах, чо часто є недопустимим в задачах семантичної сегментації. 

Для того, щоб ефективно зменшити вплив помилкової розмітки, необхідно вилучити її з процесу навчання нейронної мережі. Якщо неможливо вилучити неправильно розмічені приклади з набору даних до початку навчання, це можна робити ітеративно в процесі навчання. Такі функції втрат, як перехресна ентропія, або фокальна функція втрат призначають експоненційно високе значення для неправильних прогнозів нейронних мереж. Це має шкідливий ефект при наявності помилкової розмітки в тренувальному наборі даних - правильні прогнози на неправильно-розмічених даних створюють конфліктні градієнти та знижують впевненість прогнозів нейронної мережі.

Для виключення неправильної розмітки в процесі навчання запропоновано обмеження функції втрат зверху:

\begin{equation*}
	\mathcal{L} \rceil = min(L, \theta)
\end{equation*}

де $\theta$ - поріг обмеження функції втрат.

Графіки обмежених зверху функцій втрат зображено на рисунку \ref{fig:trimmed_losses}.
\ref{fig:trimmed_losses}
\begin{figure}
	\centering
	\includegraphics[width=12cm]{trimmed_losses_en.png}
	\caption{Приклади обмежених зверху функцій втрат}
	\label{fig:trimmed_losses}
\end{figure} 

Для функції обмеження зверху градієнт визначено лише на проміжку $(-\inf, \theta]$, тому для проміжку $(\theta, \inf)$ градієнт встановлено рівним нулю:

\begin{equation*}
\mathcal{\nabla} min(L, \theta) = 
\begin{cases}
	1 &\text{$L \in (-\inf, \theta]$}\\
	0 &\text{$L \in (\theta, \inf)$}
\end{cases}
\end{equation*}

Таким чином, приклади з занадто великою похибкою (переважно з помилковою розміткою) ефективно виключаються з навчання. 

Окрім прикладів з неправильною розміткою, з навчання випадково будуть виключені приклади, що занадто складні для вивчення нейронною мережею на ранніх етапах, що може сповільнити процес, або взагалі зупинити його. Щоб запобігти сповільненню процесу, запропоновано використання багатозадачного навчання з використанням додаткової більш загальної задачі. 

В такому випадку, обмеження функції втрат використовується лише для оригінальної задачі, а більш загальна додаткова задача використовує оригінальну функцію втрат без обмеження. Таким чином, завжди існують градієнти від більш загальної розмітки, що спонукають навчання на прикладах, для яких немає градієнтів через обмеження функції втрат. Архітектуру нейронної мережі та розподіл градієнтів детальніше розглянуто в розділі \ref{nn-arch}



\subsection{Архітектура багатозадачної нейронної мережі}
\label{nn-arch}

Для того, щоб основна і додаткова задачі оновлювали параметри нейронної мережі, що відповідають за виділення ознак, використано схему багатозадачного навчання з жорстким розподілом параметрів. 

\paragraph{Загальна архітектура нейронної мережі}

Нейронна мережа виконана з використанням архітектури енкодер-декодер, заснована на архітектурі нейронних мереж LinkNet \cite{linknet}. Нейронна мережа складається з енкодера та двох декодерів: для задач сегментації та класифікації відповідно. В ролі енкодера можуть бути використані наявні багатостадійні архітектури, такі як VGGNet, ResNet, EfficientNet та ін. Карти ознак після кожного етапу просторового зменшення використовуються як входи для декодера сегментації, для декодера класифікації використовується карта ознак з найглибшого шару енкодера. Узагальнену архітектуру зображено на рисунку \ref{fig:my_net_arch} 

\begin{figure}
	\centering
	\includegraphics[width=16cm]{my_ne_arch.png}
	\caption{Загальна архітектура нейронної мережі з декодером та класифікатором}
	\label{fig:my_net_arch}
\end{figure} 

Нехай нейронну мережу енкодера визначено як $F_{encoder}$. Тоді для вхідного зображення $x \in \mathcal{R} ^ {3 \times H \times W}$,  $v_1, v_2, ... v_i, ... v_n$ - набір карт ознак, так що $v_i \in \mathcal{R} ^ {c_i \times \frac{H}{i} \times \frac{W}{i}}$, де $c_i$ - кількість каналів для кожної з карт ознак, а $n$ - кількість стадій енкодера (залежить від архітектури):

\begin{equation*}
	v_1, v_2 ... v_n = F_{encoder}(x, \theta_{enc})
\end{equation*}

де $\theta_{enc}$ - набір параметрів енкодера.

Тоді, нейронні мережі декодера сегментації та класифікації можна визначити як $F_{seg}$ та $F_{cls}$ відповідно. Для набору карт ознак, що генерує енкодер, маємо:

\begin{align*}
	M_{seg} &= F_{seg}((v_1, v_2 ... v_n), \theta_{seg}) \\
	C_{cls} &= F_{cls}((v_n), \theta_{cls})
\end{align*}

де $\theta_{seg}$ та $\theta_{cls}$ - набори параметрів декодерів сегментації та класифікації відповідно.

Для пришвидшення процесу навчання, використано трансферне навчання: набір параметрів енкодера $\theta_{enc}$ ініціалізується з використанням параметрів, отриманих після навчання енкодера на наборі даних Imagenet \cite{imagenet}. Декодери ініціалізується зв використанням методу Хе: $\theta \in \mathcal{U}(-b, b)$, де $b$ - константа залежна від типу шару \cite{kaiming_uniform}

\paragraph{Структура декодера класифікації}
Структура декодера класифікації є важливою складовою успішного навчання при використанні обмеженої функції втрат в задачі класифікації. Основними задачами декодеру класифікації є провадження градієнтів до енкодера у випадку фільтрації неправильної розмітки в задачі сегментації, а також покращення роздільності ознак найглибшого шару енкодера.

Оскільки, в даному випадку, на зображенні може бути декілька об'єктів, а задача класифікації є задачею навчання за набором зразків, декодер класифікації має враховувати як глобальний просторовий контекст, так і локальні ознаки, притаманні об'єктам. Для цього, першим шаром класифікатора є конкатенація результатів двох операцій глобальної підвибірки: з операцією усереднення (GlobalAvgPooling), та вибору максимума (GlobalMaxPooling) для кожного з каналів карти ознак енкодера. 

Для підвищення роздільності ознак, класифікатор являє собою лінійну функцію, що спонукає енкодер до формування лінійно-роздільних представлень. 

Структура декодера класифікації зображена на рисунку \ref{fig:my_cls_arch}.
\begin{figure}
	\centering
	\includegraphics[width=8cm]{my_cls_arch.png}
	\caption{Структура декодера класифікації}
	\label{fig:my_cls_arch}
\end{figure} 

 
\paragraph{Процедура навчання нейронної мережі}
Під час навчання нейронної мережі використовується стандартний алгоритм зворотного поширення помилки з оптимізатором Adam \cite{adam-optimizer}. 

Для кожної з задач окремо обчислюється функція втрат
%2 страницы
%Использование image-level классов как подсказки для улучшения признаков, которые выучивает нейросеть  во время обучения
%	Помощь в разделении признаков на самом глубоком уровне сети
%	Возможность использования semi-supervised для неразмеченной сегментации
%	Важность average+max пулинга



% 10 страниц ------------------------------------------------------------------------
\section{Метод зниження кількості хибно-позитивних прогнозів нейронної мережі за рахунок використання результатів семантично-близьких задач}

% 5 страниц
\subsection{Використання задачі класифікації для покращення семантичної сегментації}

% 2 страницы
Вероятностная модель P(S | C) при рассмотрении сегментации как попиксельной классификации при условии, что классификатор уровня картинки выдал свой вердикт

% 1 страница
Совмещение классификатора уровня картинки через умножение вероятностей

% 1 страница
Обоснование связи с соответствующим обучением

% 1 страинца
Обоснование уменьшения false positives


% 5 старниц
\subsection{Використання близьких задач до задачі класифікації}

% 2 страницы
Внесение uncertainty через преобразование классификации в регрессию, усреднения с регрессией и последующей квантизацией


% 3 страницы
Регуляризация преобразования в регрессию





% 10 страниц ------------------------------------------------------------------------
\section{Метод сегментації важливих для класифікації ознак зображення в умовах відсутності розмітки для сегментації в навчальному наборі даних}

На основі двох представлених методів, запропоновано метод навчання з частковим залученням вчителя та метод пост-обробки, що дозволяє виконувати  сегментацію важливих для класифікації ознак. Даний метод складається з двох етапів: етапу навчання та етапу прогнозування. 

Використані позначення:



$x$ - вхідне зображення енкодера розмірами $3 \times H \times W$ для RGB зображень

$f_{encoder}(x)$ - функція енкодера ознак

$v_e$ - вихідна карта ознак енкодера, розмірами $C \times \frac{H}{r} \times \frac{W}{r}$, де $r$ - константа масштабування

$f_{classifier}$ - функція декодера класифікації

$f_{segmentation}$ - функція декодера сегментації

\subsection{Напівавтоматичне навчання ШНМ в задачі сегментації}

Для навчання декодера сегментації з частковим залученням вчителя, запропоновано 

\begin{align}
v_e &= f_{encoder}(x) \\
C &= f_{classifier}(v_e ) \\
M &= f_{segmentation}(v_e)
\end{align}

\begin{equation}
M_{refined} = \sigma(M) \circ C
\end{equation}

\begin{equation}
	\sigma = \frac{1}{1 + e^{-M}}
\end{equation}

\begin{equation}
C_{refined} = \frac {\sum_{h}^{H} \sum_{w}^{W} M_{refined(hw)}}{\sum_{h}^{H} \sum_{w}^{W} \sigma (M_{hw})}
\end{equation}

\subsection{Прогнозування результатів сегментації}

На етапі прогнозування використовується як декодер класифікації, так і декодер, що відповідає за задачу сегментації. Тільки у тому випадку, коли вихід декодера класифікації перевищує заданий поріг $T_c$, виконується процедура декодування сегментації.

Оскільки виходи декодера сегментації $M = D(X)$ є неперервними, а їхній масштаб визначається процесом навчання, поріг бінаризації сегментації $T_s$ може бути різним для різних зображень. Для вибору оптимального порогу $T_s$ на кожному з вхідних зображень, в процесі пост-обробки запропоновано використати адаптивну бінарізацію за методом Оцу \cite{otsu}, щоб уникнути необхідності калібрації прогнозів нейронної мережі.

Для цього, вихід декодера сегментації $M$ квантизується до 256 значень $M_q$, після чого ітеративно знаходиться поріг $T_s$, що мінімізує дисперсію всередині класів, яка визначається як зважена сума дисперсій класів переднього та заднього плану:

\begin{equation*}
\sigma_{w}^{2}(T_s)=min: \; \omega_{0}(t)\sigma_{0}^{2}(t)+\omega_{1}(t)\sigma_{1}^{2}(t)
\end{equation*}

Тут $\omega_0$, $\omega_1$ - ймовірності класів при розділенні порогом $t$, а $\sigma_0^2$ та $\sigma_1^2$ - дисперсії класів. 

Після виконання бінаризації, над отриманою маскою $M_t = M_q > T_s$ виконується морфологічна операція ерозії \cite{morph_opening} з квадратним ядром розміру 1\% від розміру зображення для того, щоб позбутися малих можливо хибно-позитивних регіонів маски: 

\begin{equation*}
M_e = M_t \ominus k
\end{equation*}
де $k$ - ядро ерозії.

Приклад роботи описаного алгоритму по кроках зображено на рисунку \ref{fig:res_unsup_decoding}.

% фигуру с алгоритмом сюда и картинку с примерами каждого из шагов
\begin{figure}[H]
	\centering
	\includegraphics[width=14cm]{res_unsup_decoding.png}
	\caption{Приклад роботи сегментації на зображенні меланоми}
	\label{fig:res_unsup_decoding}
\end{figure} 

Для наочності, контури маски зображено на оригінальному зображенні (червоним).

% 2 страницы ------------------------------------------------------------------------
\subsection{Висновки до другого розділу}
% Как круо все получилось и пора показать эксперименты
% В экспериментах надо показать сравнение shap и полученного метода для сегментации