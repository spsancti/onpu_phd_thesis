\chapter{Методи поєднання задач глибинного багатозадачного навчання}
Використання комбінації декількох задач машинного навчання може сприяти вивченню кращих наборів ознак, та підвищити точність роботи нейронних мереж. Також, можливе сумісне використання прогнозів декількох задач для уточнення кожного з окремих прогнозів, так і побудови нових. 


% 10 страниц ------------------------------------------------------------------------
\section{Метод багатозадачного навчання ШНМ в умовах частково помилкової розмітки семантичної сегментації}

В умовах частково-помилкової розмітки даних виникає потреба зменшення впливу неправильно розмічених прикладів на процес навчання, та їх ефективна фільтрація. Часто на одному зображенні можуть бути розташовані як коректно-розмічені, так і некоректно-розмічені об'єкти. Для підвищення точності навчання нейронних мереж в таких умовах, запропоновано використати метод багатозадачного навчання з використанням похідної більш загальної задачі.

\subsection{Генерація похідної задачі до задачі семантичної сегментації}

Семантично-близькими називають задачі, що мають однакові вхідні дані, та пов'язані вихідні дані.

На відміну від \cite{arxiv:1412.0069}, що спирається на вивчення більш детальних семантично-близьких задач, в розробленому методі використання більш точних даних, для загальніших задач дозволяє покращити роздільність внутрішніх представлень нейронної мережі, що, в свою чергу, покращує результати на вихідній задачі. Також, оскільки задачі є семантично близькими, не відбувається конфлікту градієнтів, що є типовим при навчанні семантично-різнорідних задач \cite{gradient_conflict}.

Оскільки задача семантичної сегментації може бути розглянута як задача піксельної класифікації, можна розглядати задачу класифікації всього зображення як більш загальну до неї. В такому контексті, класифікація буде окремим випадком навчання за набором зразків \cite{multiinstance}: замість розмітки кожного з об'єктів для всіх класів на зображенні, зображення являє собою мішок з одним, чи декількома об'єктами та відповідним маркуванням, чи є об'єкти заданих класів на ньому.

Попередній аналіз показав, що неточна розмітка в задачах сегментації полягає в наявності зайвих, або у відсутності деяких розмічених пікселів, або об'єктів. Наявність такої неточної розмітки дозволяє створити на її основі точну розмітку для класифікації.

Нехай для зображення $x \in \mathcal{R}^{3 \times H \times W}$ існує маска сегментації $y_s \in \mathcal{R}^{C \times H \times W}$ де $C$ - кількість класів, а $H$ та $W$ висота та ширина зображення відповідно. Якщо в масці сегментації є хоча б один розмічений об'єкт класу $с$, встановлюється мітка відповідного класу $y_c \in (0, 1)^C$ в розмітці задачі класифікації:

\begin{equation}
	y_c = t < \sum_{i}^{H} \sum_{j}^{W} y_{s_{ij}}
\end{equation}

де $t$ - поріг мінімального розміру об'єкта в пікселях

Згенерована таким чином задача класифікації має меншу ймовірність хибної розмітки.

\subsection{Автоматична фільтрація помилкової розмітки}
Маючи велику кількість параметрів, сучасні нейронні мережі здатні до запам'ятовування тренувального набору даних замість вивчення корисних ознак для узагальнення на інші набори даних (перенавчання). В умовах наявності помилкової розмітки в тренувальному наборі даних, нейронні мережі схильні до вивчення і помилок розмітки на протязі навчання. 

Традиційні методи запобігання перенавчанню, такі як аугментація даних, регуляризація ваг мережі, та завчасна зупинка навчання хоча і показують покращені результати, але можуть виявитися недостатніми в умовах великої ймовірності помилок в навчальних даних. Також, вони можуть погіршити якість навчання через зменшення ємності нейронної мережі, або, при надмірному використанні, можуть спонукати нейронну мережу акцентувати увагу на текстурах, чо часто є недопустимим в задачах семантичної сегментації. 

Для того, щоб ефективно зменшити вплив помилкової розмітки, необхідно вилучити її з процесу навчання нейронної мережі. Якщо неможливо вилучити неправильно розмічені приклади з набору даних до початку навчання, це можна робити ітеративно в процесі навчання. Такі функції втрат, як перехресна ентропія, або фокальна функція втрат призначають експоненційно високе значення для неправильних прогнозів нейронних мереж. Це має шкідливий ефект при наявності помилкової розмітки в тренувальному наборі даних - правильні прогнози на неправильно-розмічених даних створюють конфліктні градієнти та знижують впевненість прогнозів нейронної мережі.

Для виключення неправильної розмітки в процесі навчання запропоновано обмеження функції втрат зверху:

\begin{equation}
	\mathcal{L} \rceil = min(L, \theta)
\end{equation}

де $\theta$ - поріг обмеження функції втрат.

Графіки обмежених зверху функцій втрат зображено на рисунку \ref{fig:trimmed_losses}.
\ref{fig:trimmed_losses}
\begin{figure}
	\centering
	\includegraphics[width=12cm]{trimmed_losses_en.png}
	\caption{Приклади обмежених зверху функцій втрат}
	\label{fig:trimmed_losses}
\end{figure} 

Для функції обмеження зверху градієнт визначено лише на проміжку $(-\inf, \theta]$, тому для проміжку $(\theta, \inf)$ градієнт встановлено рівним нулю:

\begin{equation}
\mathcal{\nabla} min(L, \theta) = 
\begin{cases}
	1 &\text{$L \in (-\inf, \theta]$}\\
	0 &\text{$L \in (\theta, \inf)$}
\end{cases}
\end{equation}

Таким чином, приклади з занадто великою похибкою (переважно з помилковою розміткою) ефективно виключаються з навчання. 

Окрім прикладів з неправильною розміткою, з навчання випадково будуть виключені приклади, що занадто складні для вивчення нейронною мережею на ранніх етапах, що може сповільнити процес, або взагалі зупинити його. Щоб запобігти сповільненню процесу, запропоновано використання багатозадачного навчання з використанням додаткової більш загальної задачі. 

В такому випадку, обмеження функції втрат використовується лише для оригінальної задачі, а більш загальна додаткова задача використовує оригінальну функцію втрат без обмеження. Таким чином, завжди існують градієнти від більш загальної розмітки, що спонукають навчання на прикладах, для яких немає градієнтів через обмеження функції втрат. Архітектуру нейронної мережі детальніше розглянуто в розділі \ref{nn-arch}



\subsection{Архітектура багатозадачної нейронної мережі}
\label{nn-arch}

Для того, щоб основна і додаткова задачі оновлювали параметри нейронної мережі, що відповідають за виділення ознак, використано схему багатозадачного навчання з жорстким розподілом параметрів. 

\paragraph{Загальна архітектура нейронної мережі}

Нейронна мережа виконана з використанням архітектури енкодер-декодер, заснована на архітектурі нейронних мереж LinkNet \cite{linknet}. Нейронна мережа складається з енкодера та двох декодерів: для задач сегментації та класифікації відповідно. В ролі енкодера можуть бути використані наявні багатостадійні архітектури, такі як VGGNet, ResNet, EfficientNet та ін. Карти ознак після кожного етапу просторового зменшення використовуються як входи для декодера сегментації, для декодера класифікації використовується карта ознак з найглибшого шару енкодера. Узагальнену архітектуру зображено на рисунку \ref{fig:my_net_arch} 

\begin{figure}
	\centering
	\includegraphics[width=16cm]{my_ne_arch.png}
	\caption{Загальна архітектура нейронної мережі з декодером та класифікатором}
	\label{fig:my_net_arch}
\end{figure} 

Нехай нейронну мережу енкодера визначено як $F_{encoder}$. Тоді для вхідного зображення $x \in \mathcal{R} ^ {3 \times H \times W}$,  $v_1, v_2, ... v_i, ... v_n$ - набір карт ознак, так що $v_i \in \mathcal{R} ^ {c_i \times \frac{H}{i} \times \frac{W}{i}}$, де $c_i$ - кількість каналів для кожної з карт ознак, а $n$ - кількість стадій енкодера (залежить від архітектури):

\begin{equation}
	\label{eqn:enc_features}
	v_1, v_2 ... v_n = F_{encoder}(x, \theta_{enc})
\end{equation}

де $\theta_{enc}$ - набір параметрів енкодера.

Тоді, нейронні мережі декодера сегментації та класифікації можна визначити як $F_{seg}$ та $F_{cls}$ відповідно. Для набору карт ознак, що генерує енкодер, маємо:

\begin{align}
	\label{eqn:m_seg}
	M_{seg} &= F_{seg}((v_1, v_2 ... v_n), \theta_{seg}) \\
	\label{eqn:c_cls}
	C_{cls} &= F_{cls}((v_n), \theta_{cls})
\end{align}

де $\theta_{seg}$ та $\theta_{cls}$ - набори параметрів декодерів сегментації та класифікації відповідно.

Для пришвидшення процесу навчання, використано трансферне навчання: набір параметрів енкодера $\theta_{enc}$ ініціалізується з використанням параметрів, отриманих після навчання енкодера на наборі даних Imagenet \cite{imagenet}. Декодери ініціалізується зв використанням методу Хе: $\theta \in \mathcal{U}(-b, b)$, де $b$ - константа залежна від типу шару \cite{kaiming_uniform}

\paragraph{Структура декодера семантичної сегментації}
Структура декодера сегментації ідентична декодеру архітектури UNet \cite{unet} за виключенням останнього шару. Декодер складається з декількох стадій, кожна з яких має розміри карт ознак відповідно до карт ознак енкодера. 

Оскільки в задачі сегментації з частково-помилковою розміткою одному пікселю може бути призначено декілька класів одночасно, необхідно це враховувати при використанні обмежених функцій втрат. Для формування фінальної карти сегментації використовується спеціальна версія блоку декодера. Структуру окремих стадій показано на рисунку \ref{fig:my_decoder_block_arch}.

\begin{figure}
	\centering
	\includegraphics[width=14cm]{my_decoder_block_arch.png}
	\caption{Структура стадій декодеру сегментації}
	\label{fig:my_decoder_block_arch}
\end{figure} 

В ролі вхідної карти ознак для найпершого шару декодера використовується останній шар енкодера. 

\paragraph{Структура декодера класифікації}
Структура декодера класифікації є важливою складовою успішного навчання при використанні обмеженої функції втрат в задачі класифікації. Основними задачами декодеру класифікації є провадження градієнтів до енкодера у випадку фільтрації неправильної розмітки в задачі сегментації, а також покращення роздільності ознак найглибшого шару енкодера.

Оскільки, в даному випадку, на зображенні може бути декілька об'єктів, а задача класифікації є задачею навчання за набором зразків, декодер класифікації має враховувати як глобальний просторовий контекст, так і локальні ознаки, притаманні об'єктам. Для цього, першим шаром класифікатора є конкатенація результатів двох операцій глобальної підвибірки: з операцією усереднення (GlobalAvgPooling), та вибору максимума (GlobalMaxPooling) для кожного з каналів карти ознак енкодера. 

Для підвищення роздільності ознак, класифікатор являє собою лінійну функцію, що спонукає енкодер до формування лінійно-роздільних представлень. Також, для зменшення впливу відносного масштабу карт ознак, використовується шар пакетної нормалізації перед лінійним шаром. 

Структура декодера класифікації зображена на рисунку \ref{fig:my_cls_arch}.

\begin{figure}
	\centering
	\includegraphics[width=8cm]{my_cls_arch.png}
	\caption{Структура декодера класифікації}
	\label{fig:my_cls_arch}
\end{figure} 

 
\paragraph{Агрегація функцій втрат під час навчання}
Під час навчання нейронної мережі використовується стандартний алгоритм зворотного поширення помилки з оптимізатором Adam \cite{adam-optimizer}. 

Для кожної з задач окремо обчислюється функція втрат. Для навчання декодера сегментації використовується обмежена зверху функція втрат, в той час як для декодера класифікації - звичайна

Загальне значення функції втрат визначається як арифметичне середнє між індивідуальними значеннями:

\begin{equation}
	L_{total} = \frac{L_{seg} \rceil + L_{cls}}{2}
\end{equation}
 
Відповідно, загальний градієнт функції втрат буде сумою градієнтів складових частин:

\begin{equation}
	\nabla L_{total} = \frac{\nabla L_{seg} \rceil + \nabla  L_{cls}}{2}
\end{equation}

Поріг обмеження функції втрат для задачі сегментації є параметром алгоритму навчання та має обиратися емпірично в залежності від рівня помилок в розмітці. Таким чином, забезпечується "прохід" градієнтів для оновлення параметрів від хоча б однієї функції втрат для кожного вхідного прикладу. 


% 10 страниц ------------------------------------------------------------------------
\subsection{Метод зниження хибно-позитивних результатів семантичної сегментації за рахунок використання задачі класифікації}

Оскільки одна нейронна мережа одночасно вивчає як задачу сегментації, так і задачу класифікації, стає можливою імплементація фільтрування хибно-позитивних ознак без підвищення витрат часу на етапі прогнозування результатів. В такому випадку можливі два варіанти комбінації результатів двох задач: послідовний і паралельний.

Нехай $C_{cls} \in \mathcal{R}^{C}$ та $M_{seg} \in \mathcal{R}^{C \times H \times W}$- результати декодерів класифікації та сегментації відповідно, значення яких знаходяться на проміжку  $(- \infty, + \infty)$ (логіти).

Для отримання результатів на проміжку $[0, 1]$ використовується логістична сигмоїдна функція активації:

\begin{equation}
	\sigma(x) = \frac{1}{1 + e^{-x}}
\end{equation}

Послідовний варіант полягає у відкиданні результатів сегментації, якщо результат класифікації менший, за деякий поріг $t_{cls}$:

\begin{equation}
M_{refined} = 	
\begin{cases}
	\sigma(M_{seg})& \text{якщо } \sigma(C_{cls}) > t_{cls}\\
	0^{C \times H \times W} &\text{якщо } \sigma(C_{cls}) \leq t_{cls}
\end{cases}
\end{equation}

Такий варіант має декілька суттєвих недоліків:
\begin{itemize}
	\item Необхідність вибору додаткового параметра $\theta_{cls}$ вносить додаткову можливість помилки; неправильний підбір цього параметра може призвести до значного збільшення хибно-негативних результатів.
	\item Можливість розповсюдження помилки класифікатора виникає через значно меншу кількість параметрів порівняно з декодером сегментації.
\end{itemize}

Паралельний варіант полягає у зважуванні карти сегментації за допомогою нормованих логітів класифікатора. Першим кроком є трансформація логітів сегментації та класифікації в некалібровані оцінки на проміжку $[0, 1]$:

\begin{align}
	\label{eqn:m_hat_seg}
	\hat{M}_{seg} &= \sigma(M_{seg}) \\
	\label{eqn:c_hat_cls}
	\hat{C}_{cls} &= \sigma(C_{cls})	
\end{align}

Ці оцінки мають ті самі розмірності, що й оригінальні маска та класи, для зручності репрезентації операцій додано додаткові розмірності до вектору класів: $\hat{M}_{seg} \in \mathcal{R}^{C \times H \times W}$ та $\hat{C}_{cls} \in \mathcal{R}^{C \times 1 \times 1}$ 

Зважування карти сегментації відбувається за допомогою добутку Адамара між матрицями $\hat{M}_{seg}$ та $\hat{С}_{cls}$

\begin{equation}
	M_{refined} = \hat{M}_{seg} \circ \hat{С}_{cls}
\end{equation}

Графічну репрезентацію структури зображено на рисунку \ref{fig:my_net_arch_comb}.

\begin{figure}
	\centering
	\includegraphics[width=16cm]{my_net_arch_comb.png}
	\caption{Структура об'єднання прогнозів класифікації та сегментації}
	\label{fig:my_net_arch_comb}
\end{figure} 

Паралельний варіант має перевагу над послідовним у відсутності додаткового параметру навчання. Також, зважені карти сегментації допомагають збереженню більшої кількості інформації для етапу пост-обробки масок сегментації. 

Однак, в разі використання добутку двох сигмоїдних функцій, потрібно зважати, що змінюється центральна точка, і, відповідно поріг бінаризації в подальшій обробці. Навіть у випадку співпадання значень класифікації та сегментації, фінальний прогноз буде відрізнятися від послідовного підходу. 

Графік сигмоїдної функції, та добутку двох ідентичних сигмоїдних функцій зображено на рисунку \ref{fig:sig_sig_sqr}.

\begin{figure}
	\centering
	\includegraphics[width=12cm]{sig_sig_sqr.png}
	\caption{Структура декодера класифікації}
	\label{fig:sig_sig_sqr}
\end{figure}

При використанні того самого порогу бінаризації для карт сегментації, зменшиться кількість позитивних пікселів в результаті.

% 10 страниц ------------------------------------------------------------------------
\section{Метод сегментації важливих для класифікації ознак зображення в умовах відсутності розмітки для сегментації в навчальному наборі даних}

На основі двох представлених методів, запропоновано метод навчання з частковим залученням вчителя та метод пост-обробки, що дозволяє виконувати  сегментацію важливих для класифікації ознак. Даний метод складається з двох етапів: етапу навчання та етапу прогнозування. 

Відповідно до попереднього розділу використані позначення:


$x$ - вхідне зображення енкодера розмірами $3 \times H \times W$

$F_{encoder}(x, \theta_{enc})$ - функція енкодера зображень,

$\theta_{enc}$ - набір параметрів нейронної мережі енкодера,

$v_1, v_2, ... v_i, ... v_n$ - набір карт ознак енкодера, відповідно до рівняння \ref{eqn:enc_features},

$F_{seg}$ та $F_{cls}$ - нейронні мережі декодера сегментації та класифікації, 

$M_{seg}$ та $C_{cls}$ - результати сегментації та класифікації відповідно до рівнянь \ref{eqn:m_seg} та \ref{eqn:c_cls}

$\hat{M}_{seg}$ та $\hat{C}_{cls}$ - нормовані результати сегментації та класифікації відповідно до рівнянь \ref{eqn:m_hat_seg} та \ref{eqn:c_hat_cls}

\subsection{Напівавтоматичне навчання ШНМ в задачі сегментації}

Для покращення можливостей інтерпретації прогнозів моделей, було вдосконалено метод сегментації важливих для класифікації ознак зображення за рахунок використання методів багатозадачного навчання, що дозволило його використання в умовах відсутності розмітки семантичної сегментації в навчальному наборі даних. 

В основі запропонованого методу лежить ітеративне уточнення карти ознак сегментації за допомогою направлення градієнтів від задачі класифікації. В даному випадку, під час навчання декодер сегментації використовується в ролі механізму уваги, що навчається автоматично за рахунок градієнтів до задачі класифікації.

Першим етапом, обчислюється уточнена ознак класифікації. Для цього, обчислюється добуток Адамара між нормованим за допомогою сигмоїдної функції виходом декодера сегментації та логітами класифікації:

\begin{equation}
	M_{unsup} = \hat{M}_{seg} \circ C_{cls}
\end{equation}

Далі, для отримання результату класифікації виконується сумація елементів $M_{unsup}$ з нормалізацією за сумою елементів оригінальної ненормалізованої карти сегментації:

\begin{equation}
	C_{unsup} = \frac{\sum_{h=0}^H \sum_{w=0}^{W} M_{unsup(h,w)}}{\sum_{h=0}^H \sum_{w=0}^{W} M_{seg(h,w)} + c}
\end{equation}

Для чисельної стабільності, до знаменника додано малу константу $c \approx 10^{-5}$

Оскільки масштаб нормованого виходу декодера сегментації знаходиться на проміжку $[0, 1]$, використання добутку Адамара дозволяє розглядати $\hat{M}_{seg}$ як карту важливості регіонів для задачі класифікації. В процесі навчання нейронної мережі, така структура поєднання задач спонукає нейронну мережу до призначення високих значень ($\hat(M)_{seg} \rightarrow 1$) для важливих ознак, що є спільними на зображеннях з навчального набору даних.

Для запобігання вивченню нейронною мережею карт сегментації, що складаються виключно з високих значень, необхідна така ініціалізація параметру зсуву останнього шару декодера сегментації $F_{seg}$, щоб активації, за замовчуванням, були близькими до нуля. Для сигмоїдної функції активації таке значення дорівнює $-4.6$


\subsection{Прогнозування результатів сегментації}

На етапі прогнозування використовується як декодер класифікації, так і декодер, що відповідає за задачу сегментації. Тільки у тому випадку, коли вихід декодера класифікації перевищує заданий поріг $T_c$, виконується процедура декодування сегментації.

Оскільки виходи декодера сегментації $M_{unsup}$ є неперервними, а їхній масштаб визначається процесом навчання, поріг бінаризації сегментації $T_{seg}$ може бути різним для різних зображень. Для вибору оптимального порогу $T_{seg}$ на кожному з вхідних зображень, в процесі пост-обробки запропоновано використати адаптивну бінарізацію за методом Оцу \cite{otsu}, щоб уникнути необхідності калібрації прогнозів нейронної мережі.

Для цього, вихід декодера сегментації $M_{unsup}$ квантизується до 256 значень $M_q$, після чого ітеративно знаходиться поріг $T_{seg}$, що мінімізує дисперсію всередині каналів маски для кожного з класів, яка визначається як зважена сума дисперсій класів переднього та заднього плану:

\begin{equation}
\sigma_{w}^{2}(T_{seg})=min: \; \omega_{0}(t)\sigma_{0}^{2}(t)+\omega_{1}(t)\sigma_{1}^{2}(t)
\end{equation}

Тут $\omega_0$, $\omega_1$ - ймовірності класів при розділенні порогом $t$, а $\sigma_0^2$ та $\sigma_1^2$ - дисперсії класів. 

Після виконання бінаризації, над отриманою маскою $M_t = M_q > T_{seg}$ виконується морфологічна операція ерозії \cite{morph_opening} з квадратним ядром розміру 1\% від розміру зображення для того, щоб позбутися малих можливо хибно-позитивних регіонів маски: 

\begin{equation}
M_e = M_t \ominus k
\end{equation}

де $k$ - ядро ерозії.

Результатом такого перетворення э бінаризована карта сегментації, в якій розмічено найбільш вірогідні ознаки, що вплинули на результат класифікації. 

% 2 страницы ------------------------------------------------------------------------
\subsection{Висновки до третього розділу}
